{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7959365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7de1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c13faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73b58173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"./db/cafe_db\")\n",
    "    \n",
    "    return cafe_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61104cd4",
   "metadata": {},
   "source": [
    "### 3개 도구 정의 및 LLM에 바인딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d01426f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"./db/cafe_db\")\n",
    "    \n",
    "    return cafe_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d16a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 도구 정의\n",
    "# 웹 검색 도구\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "    \n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ac23fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 위키피디아 검색 도구\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    \n",
    "    formatted_docs = [\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "    ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ecf3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-4-scout-17b-16e-instruct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58787b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm\n",
    ")\n",
    "\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d543fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 카페 메뉴 검색 도구\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for cafe menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    cafe_db = FAISS.load_local(\n",
    "        \"./db/cafe_db\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 카페 메뉴 정보를 찾을 수 없습니다.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b028031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. 도구를 LLM에 바인딩\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4211da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def cafe_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # 첫 번째 LLM 호출로 도구 사용 결정\n",
    "    ai_msg = llm_with_tools.invoke(user_input, config=config)\n",
    "    \n",
    "    # 도구 실행\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    \n",
    "    # 최종 답변 생성을 위한 프롬프트\n",
    "    final_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful cafe assistant. Provide accurate information based on the search results.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", ai_msg.content if ai_msg.content else \"도구를 사용하여 정보를 검색했습니다.\"),\n",
    "        (\"human\", \"검색 결과: {tool_results}\")\n",
    "    ])\n",
    "    \n",
    "    # 도구 결과를 문자열로 변환\n",
    "    tool_results_str = \"\\n\\n\".join([str(msg.content) for msg in tool_msgs])\n",
    "    \n",
    "    # 최종 답변 생성\n",
    "    final_chain = final_prompt | llm\n",
    "    return final_chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"tool_results\": tool_results_str\n",
    "    }, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "121e6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\n",
      "db_search_cafe_func: \n",
      "{'name': 'db_search_cafe_func', 'args': {'query': '아메리슋반 가격'}, 'id': '1kq1dm9yj', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': '아메리슋반 유래'}, 'id': '984cgtha5', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "질문: 아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가?\n",
      "답변: 아메리카노의 가격은 4,500원입니다. \n",
      "\n",
      "아메리카노는 에스프레소에 뜨거운 물을 더해 만든 커피입니다. \n",
      "\n",
      "아메리카노의 유래는 1940년대 미국에서 이탈리아 출신 바리스타가 에스프레소 커피를 현지인의 입맛에 맞추기 위해 물을 추가한 것이 시초라고 합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 실행 및 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 벡터 DB 생성 (최초 1회만 실행)\n",
    "    try:\n",
    "        create_cafe_vector_db()\n",
    "        print(\"카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"벡터 DB 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 질문에 답변\n",
    "    query = \"아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가?\"\n",
    "    response = cafe_search_chain.invoke(query)\n",
    "    \n",
    "    print(\"질문:\", query)\n",
    "    print(\"답변:\", response.content)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7476e4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-build-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
