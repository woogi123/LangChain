{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c9991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "768bd237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527bdb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001FAFF65C680> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001FAFFAFFD40> root_client=<openai.OpenAI object at 0x000001FAFC52AF90> root_async_client=<openai.AsyncOpenAI object at 0x000001FAFF6F6A20> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd52a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert. Answer the question. <Question>: {input}을 재료로 사용해 만들 수 있는 요리를 추천해줘')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. \"\n",
    "                                \"<Question>: {input}을 재료로 사용해 만들 수 있는 요리를 추천해줘\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589c483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 연결 (output_parser 추가)\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049c9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "input = input()\n",
    "answer = chain2.stream({\"input\": input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계란, 밥, 김치를 사용하여 만들 수 있는 요리로는 여러 가지가 있지만, 가장 대표적인 것을 추천해 드리겠습니다.\n",
      "\n",
      "1. **계란 김치밥**: \n",
      "   - 밥에 김치를 잘게 썰어 넣고, 계란을 풀어서 섞어준 후 간을 맞춰줍니다. \n",
      "   - 이것을 프라이팬에다가 만들어주면 간단하면서도 맛있는 요리가 됩니다.\n",
      "\n",
      "2. **김치 계란밥**:\n",
      "   - 프라이팬에 기름을 두르고 다진 김치를 넣고 볶아줍니다.\n",
      "   - 여기에 밥을 넣고 잘 볶아준 후, 계란을 넣고 다 섞어주면 됩니다.\n",
      "\n",
      "3. **계란탕**:\n",
      "   - 조금 더 국물 요리를 원하신다면, 계란탕을 추천해 드립니다. \n",
      "   - 김치를 잘게 썰어 넣고, 계란을 풀어서 넣은 후, 물을 추가하여 국물을 만들고 간을 맞추면 됩니다.\n",
      "\n",
      "4. **김치전**:\n",
      "   - 김치를 잘게 썰어 넣고, 여기에 계란과 밥을 섞어 전을 부쳐도 맛있습니다.\n",
      "\n",
      "이 중에서 선택하시면 간단하면서도 맛있는 요리를 만드실 수 있을 것입니다."
     ]
    }
   ],
   "source": [
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e8d5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-build-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
