{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7959365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7de1654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os, json\n",
    "\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28c13faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73b58173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"./db/cafe_db\")\n",
    "    \n",
    "    return cafe_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61104cd4",
   "metadata": {},
   "source": [
    "### 3개 도구 정의 및 LLM에 바인딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d01426f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"./db/cafe_db\")\n",
    "    \n",
    "    return cafe_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7d16a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. 도구 정의\n",
    "# 웹 검색 도구\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "    \n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ac23fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 위키피디아 검색 도구\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    \n",
    "    formatted_docs = [\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "    ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ecf3eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-4-scout-17b-16e-instruct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d58787b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm\n",
    ")\n",
    "\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d543fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 카페 메뉴 검색 도구\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for cafe menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    cafe_db = FAISS.load_local(\n",
    "        \"./db/cafe_db\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 카페 메뉴 정보를 찾을 수 없습니다.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b028031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. 도구를 LLM에 바인딩\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4211da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def cafe_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # 첫 번째 LLM 호출로 도구 사용 결정\n",
    "    ai_msg = llm_with_tools.invoke(user_input, config=config)\n",
    "    \n",
    "    # 도구 실행\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    \n",
    "    # 최종 답변 생성을 위한 프롬프트\n",
    "    final_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful cafe assistant. Provide accurate information based on the search results.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", ai_msg.content if ai_msg.content else \"도구를 사용하여 정보를 검색했습니다.\"),\n",
    "        (\"human\", \"검색 결과: {tool_results}\")\n",
    "    ])\n",
    "    \n",
    "    # 도구 결과를 문자열로 변환\n",
    "    tool_results_str = \"\\n\\n\".join([str(msg.content) for msg in tool_msgs])\n",
    "    \n",
    "    # 최종 답변 생성\n",
    "    final_chain = final_prompt | llm\n",
    "    return final_chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"tool_results\": tool_results_str\n",
    "    }, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "121e6cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\n",
      "db_search_cafe_func: \n",
      "{'name': 'db_search_cafe_func', 'args': {'query': '아메리사노 가각'}, 'id': 'q5v7g0gsy', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': '아메리사노 유래'}, 'id': 'krj3adbx1', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "질문: 아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가?\n",
      "답변: 아메리카노의 가격은 4,500원입니다.\n",
      "\n",
      "아메리카노는 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다. 원두 본연의 맛을 가장 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. \n",
      "\n",
      "아메리카노의 유래는 1940년대 이탈리아에 있습니다. 에스프레소를 즐겨 마시던 이탈리아 사람들이었지만, 미국인들이 에스프레소보다 더 묽은 커피를 선호한다는 사실을 알게 되었습니다. 그래서 에스프레소에 물을 추가한 '아메리카노'가 탄생하게 되었습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 실행 및 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 벡터 DB 생성 (최초 1회만 실행)\n",
    "    try:\n",
    "        create_cafe_vector_db()\n",
    "        print(\"카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"벡터 DB 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 질문에 답변\n",
    "    query = \"아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가?\"\n",
    "    response = cafe_search_chain.invoke(query)\n",
    "    \n",
    "    print(\"질문:\", query)\n",
    "    print(\"답변:\", response.content)               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e7bea",
   "metadata": {},
   "source": [
    "## 5-2 Few-shot 프롬프팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "682cbb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ca01a595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for cafe menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    cafe_db = FAISS.load_local(\n",
    "        \"./db/cafe_db\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 카페 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "\n",
    "# 2. Few-shot 예제 정의\n",
    "examples = [\n",
    "    HumanMessage(\"아메리카노의 가격과 특징, 그리고 커피의 역사에 대해 알려주세요.\", name=\"example_user\"),\n",
    "    AIMessage(\"카페 메뉴를 검색하고, 위키피디아에서 커피 역사 정보를 찾아보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"db_search_cafe_func\", \"args\": {\"query\": \"아메리카노\"}, \"id\": \"1\"}]),\n",
    "    ToolMessage(\"아메리카노: 가격 ₩4,500, 에스프레소와 뜨거운 물로 만든 클래식 블랙 커피, 원두 본연의 맛을 느낄 수 있음\", tool_call_id=\"1\"),    \n",
    "    AIMessage(\"아메리카노 정보를 찾았습니다. 이제 커피의 역사를 위키피디아에서 검색해보겠습니다.\", name=\"example_assistant\"),\n",
    "    AIMessage(\"\", name=\"example_assistant\", tool_calls=[{\"name\": \"wiki_summary\", \"args\": {\"query\": \"커피 역사\"}, \"id\": \"2\"}]),\n",
    "    ToolMessage(\"커피는 에티오피아에서 기원하여 아랍을 거쳐 전 세계로 전파된 음료입니다. 15세기 예멘에서 처음 재배되기 시작했으며, 17세기 유럽으로 전해져 커피하우스 문화가 발달했습니다. 산업혁명과 함께 대량 생산이 가능해지면서 현재와 같은 커피 문화가 형성되었습니다.\", tool_call_id=\"2\"),\n",
    "    AIMessage(\"아메리카노(₩4,500)는 진한 에스프레소에 뜨거운 물을 더해 만든 클래식한 블랙 커피입니다. 원두 본연의 맛을 가장 잘 느낄 수 있으며, 깔끔하고 깊은 풍미가 특징입니다. 커피는 에티오피아에서 기원하여 아랍을 거쳐 전 세계로 전파되었으며, 15세기 예멘에서 처음 재배되기 시작했습니다. 17세기 유럽으로 전해져 커피하우스 문화가 발달했고, 산업혁명과 함께 대량 생산이 가능해지면서 현재와 같은 커피 문화가 형성되었습니다.\", name=\"example_assistant\"),\n",
    "]\n",
    "\n",
    "# 3. Few-shot 프롬프트 템플릿 작성\n",
    "today = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "system = \"\"\"You are an AI assistant providing cafe menu information and general food/beverage-related knowledge.\n",
    "For information about the cafe's menu, use the db_search_cafe_func tool.\n",
    "For other general information about food, beverages, and their history, use the wiki_summary tool.\n",
    "If additional web searches are needed or for the most up-to-date information, use the tavily_search_func tool.\n",
    "\n",
    "Guidelines:\n",
    "1. For cafe menu queries, always search the menu database first\n",
    "2. For general knowledge about food/beverages, use Wikipedia\n",
    "3. For latest trends or news, use web search\n",
    "4. Provide comprehensive answers by combining multiple sources when needed\n",
    "5. Always cite the source of your information\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system + f\" Today's date is {today}.\"),\n",
    "    *examples,\n",
    "    (\"human\", \"{user_input}\"),\n",
    "    (\"placeholder\", \"{messages}\"),\n",
    "])\n",
    "\n",
    "# 4. 도구를 LLM에 바인딩\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n",
    "\n",
    "# 5. Few-shot 프롬프트를 사용한 체인 구성\n",
    "fewshot_search_chain = few_shot_prompt | llm_with_tools\n",
    "\n",
    "# 6. 도구 실행 결과를 종합하여 최종 답변을 생성하는 체인 구현\n",
    "@chain\n",
    "def advanced_cafe_chain(user_input: str, config: RunnableConfig):\n",
    "    input_ = {\"user_input\": user_input}\n",
    "    ai_msg = fewshot_search_chain.invoke(input_, config=config)\n",
    "    \n",
    "    print(\"AI가 선택한 도구들:\")\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"- {tool_call['name']}: {tool_call['args']}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"실행 중: {tool_call['name']}\")\n",
    "        \n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    \n",
    "    print(f\"총 {len(tool_msgs)}개의 도구 결과를 받았습니다.\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return fewshot_search_chain.invoke({**input_, \"messages\": [ai_msg, *tool_msgs]}, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8c004c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 카페라떼와 어울리는 디저트는 무엇인가요? 그리고 라떼의 유래에 대해서도 알려주세요.\n",
      "================================================================================\n",
      "AI가 선택한 도구들:\n",
      "- db_search_cafe_func: {'query': '카페라떼 디저트'}\n",
      "--------------------------------------------------\n",
      "실행 중: db_search_cafe_func\n",
      "총 1개의 도구 결과를 받았습니다.\n",
      "--------------------------------------------------\n",
      "최종 답변:\n",
      "카페라떼는 다양한 디저트와 잘 어울립니다. 특히 크림을 사용한 디저트인 티라미수, 크림 케이크, 마카롱 등이 추천됩니다. 이제 라떼의 유래를 알려드리겠습니다.\n",
      "\n",
      "================================================================================\n",
      "추가 테스트 질문들:\n",
      "\n",
      "1. 콜드브루의 가격과 특징을 알려주세요.\n",
      "AI가 선택한 도구들:\n",
      "- db_search_cafe_func: {'query': '콜드브루'}\n",
      "--------------------------------------------------\n",
      "실행 중: db_search_cafe_func\n",
      "총 1개의 도구 결과를 받았습니다.\n",
      "--------------------------------------------------\n",
      "답변: 콜드브루의 가격은 ₩5,000이며, 찬물에 12-24시간 우려낸 콜드브루 원액을 사용한 시원한 커피입니다. 부드럽고 달콤한 맛이 특징이며, 산미가 적어 누구나 부담 없이 즐길 수 있습니다. 얼음과 함께 시원하게 제공됩니다....\n",
      "\n",
      "2. 티라미수와 잘 어울리는 커피는 무엇인가요? 티라미수의 유래도 설명해주세요.\n",
      "AI가 선택한 도구들:\n",
      "- wiki_summary: {'query': '티라미수 유래'}\n",
      "--------------------------------------------------\n",
      "실행 중: wiki_summary\n",
      "총 1개의 도구 결과를 받았습니다.\n",
      "--------------------------------------------------\n",
      "답변: ...\n",
      "\n",
      "3. 최근 커피 트렌드는 무엇인가요?\n",
      "AI가 선택한 도구들:\n",
      "- tavily_search_func: {'query': '최근 커피 트렌드'}\n",
      "--------------------------------------------------\n",
      "실행 중: tavily_search_func\n",
      "총 1개의 도구 결과를 받았습니다.\n",
      "--------------------------------------------------\n",
      "답변: 최근 커피 트렌드는 크게 두 가지로 나뉩니다. 첫 번째는 최대한 저렴한 커피를 찾는 소비자들이며, 두 번째는 지불한 만큼 만족할 수 있는 커피를 찾는 소비자입니다. 저렴한 커피를 선호하는 소비자는 프랜차이즈와 대형 브랜드 위주로 소비하며 가성비를 중요하게 생각합니다. 가격이 오를 경우 소비량을 줄이거나 대체 음료를 찾을 가능성이 높습니다. 반면, 지불한 만...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 7. 실행 및 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 복합 질문 테스트\n",
    "    query = \"카페라떼와 어울리는 디저트는 무엇인가요? 그리고 라떼의 유래에 대해서도 알려주세요.\"\n",
    "    \n",
    "    print(f\"질문: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    response = advanced_cafe_chain.invoke(query)\n",
    "    \n",
    "    print(\"최종 답변:\")\n",
    "    print(response.content)\n",
    "    \n",
    "    # 추가 테스트 질문들\n",
    "    additional_queries = [\n",
    "        \"콜드브루의 가격과 특징을 알려주세요.\",\n",
    "        \"티라미수와 잘 어울리는 커피는 무엇인가요? 티라미수의 유래도 설명해주세요.\",\n",
    "        \"최근 커피 트렌드는 무엇인가요?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"추가 테스트 질문들:\")\n",
    "    \n",
    "    for i, additional_query in enumerate(additional_queries, 1):\n",
    "        print(f\"\\n{i}. {additional_query}\")\n",
    "        try:\n",
    "            additional_response = advanced_cafe_chain.invoke(additional_query)\n",
    "            print(f\"답변: {additional_response.content[:200]}...\")  # 처음 200자만 출력\n",
    "        except Exception as e:\n",
    "            print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06e3867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 카페 AI 어시스턴트 테스트 ===\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 완료!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 8. Gradio UI 구현 (선택사항)\n",
    "def create_gradio_interface():\n",
    "    \"\"\"\n",
    "    Gradio를 사용한 웹 인터페이스 생성\n",
    "    \"\"\"\n",
    "    import gradio as gr\n",
    "    from typing import List, Tuple\n",
    "    \n",
    "    def chat_interface(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "        try:\n",
    "            # 채팅 기록을 AI에게 전달할 수 있는 형식으로 변환\n",
    "            chat_history = []\n",
    "            for human, ai in history[-2:]:  # 최근 2개의 대화만 사용\n",
    "                chat_history.append(HumanMessage(content=human))\n",
    "                chat_history.append(AIMessage(content=ai))\n",
    "            \n",
    "            # 체인 실행\n",
    "            response = advanced_cafe_chain.invoke(message)\n",
    "            return response.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다: {str(e)}\"\n",
    "    \n",
    "    # 예제 질문들\n",
    "    example_questions = [\n",
    "        \"아메리카노의 가격과 특징을 알려주세요.\",\n",
    "        \"카페라떼와 어울리는 디저트는 무엇인가요?\",\n",
    "        \"콜드브루의 유래에 대해 설명해주세요.\",\n",
    "        \"최근 커피 트렌드를 검색해주세요.\"\n",
    "    ]\n",
    "    \n",
    "    # Gradio 인터페이스 생성\n",
    "    demo = gr.ChatInterface(\n",
    "        fn=chat_interface,\n",
    "        title=\"카페 메뉴 AI 어시스턴트\",\n",
    "        description=\"카페 메뉴 정보, 음료 추천, 음식 관련 질문에 답변해 드립니다.\",\n",
    "        examples=example_questions,\n",
    "        theme=gr.themes.Soft()\n",
    "    )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# 실행 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # 기본 콘솔 테스트\n",
    "    print(\"=== 카페 AI 어시스턴트 테스트 ===\")\n",
    "    \n",
    "    # 웹 인터페이스 실행 (선택사항)\n",
    "    demo = create_gradio_interface()\n",
    "    demo.launch()\n",
    "    \n",
    "    print(\"테스트 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827fbaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "\n",
    "# 데모 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c98f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-build-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
