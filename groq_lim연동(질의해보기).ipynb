{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2b84546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f1b28",
   "metadata": {},
   "source": [
    "프롬프트를 통해 질문 input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6a2090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"자바는 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fc2a0",
   "metadata": {},
   "source": [
    "결과 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9435812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000024077E4C890> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000240793E91F0> root_client=<openai.OpenAI object at 0x0000024076804620> root_async_client=<openai.AsyncOpenAI object at 0x00000240795C7FB0> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e82e3b3",
   "metadata": {},
   "source": [
    "여기서 답을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0303c807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 자바는 객체 지향 프로그래밍 언어입니다. 1995년에 썬 마이크로시스템즈(현재 오라클 소유)에서 제임스 고슬링에 의해 개발되었습니다. 자바는 플랫폼 독립적이며, 다양한 운영 체제에서 실행할 수 있습니다.\n",
      "\n",
      "자바의 주요 특징은 다음과 같습니다.\n",
      "\n",
      "1. **객체 지향 프로그래밍**: 자바는 객체 지향 프로그래밍 언어입니다. 이는 프로그램을 객체로 구성하고, 객체 간의 상호 작용을 통해 프로그램을 작성하는 방식입니다.\n",
      "2. **플랫폼 독립성**: 자바는 자바 가상 머신(JVM)을 통해 플랫폼 독립성을 제공합니다. JVM은 자바 코드를 실행하는 가상 머신으로, 다양한 운영 체제에서 실행할 수 있습니다.\n",
      "3. **간결한 문법**: 자바는 간결한 문법을 가지고 있습니다. 자바는 C++과 유사한 문법을 가지고 있지만, 더욱 간단하고 명확합니다.\n",
      "4. **강력한 보안**: 자바는 강력한 보안 기능을 제공합니다. 자바는 메모리 관리, 데이터 유효성 검사, 보안 정책 등을 통해 보안 위협을 방지합니다.\n",
      "5. **대규모 커뮤니티**: 자바는 대규모 커뮤니티를 가지고 있습니다. 자바는 전 세계적으로 널리 사용되며, 많은 개발자들이 자바를 사용하고 있습니다.\n",
      "\n",
      "자바는 다양한 분야에서 사용됩니다. 예를 들어, 웹 개발, 모바일 앱 개발, 데스크톱 애플리케이션 개발, 게임 개발 등에 사용됩니다.\n",
      "\n",
      "자바의 주요 구성 요소는 다음과 같습니다.\n",
      "\n",
      "1. **자바 언어**: 자바 언어는 자바의 핵심입니다. 자바 언어는 객체 지향 프로그래밍을 지원하며, 다양한 기능을 제공합니다.\n",
      "2. **자바 가상 머신(JVM)**: JVM은 자바 코드를 실행하는 가상 머신입니다. JVM은 플랫폼 독립성을 제공합니다.\n",
      "3. **자바 라이브러리**: 자바 라이브러리는 자바의 기능을 확장하는 라이브러리입니다. 자바 라이브러리는 다양한 기능을 제공합니다.\n",
      "\n",
      "자바의 버전은 다음과 같습니다.\n",
      "\n",
      "1. **자바 1.0**: 자바 1.0은 자바의 첫 번째 버전입니다. 1995년에 출시되었습니다.\n",
      "2. **자바 8**: 자바 8은 자바의 최신 버전입니다. 2014년에 출시되었습니다.\n",
      "\n",
      "자바는 널리 사용되는 프로그래밍 언어입니다. 자바는 다양한 분야에서 사용되며, 대규모 커뮤니티를 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173662bf",
   "metadata": {},
   "source": [
    "## LCEL\n",
    "Prompt + LLM Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206e159",
   "metadata": {},
   "source": [
    "1. PromptTemplate 사용해서 model 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c87d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. \"\n",
    "                                \"<Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "926a7b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 연결 (output_parser 추가)\n",
    "output_parser = StrOutputParser()\n",
    "chain2 = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ad6eeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. \n",
      "\n",
      "1. **데이터 수집**: 우선, 인공지능 모델을 학습시키기 위해 관련된 데이터를 수집합니다. \n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 깨끗하고 올바른 형식으로 변환되어야 합니다.\n",
      "\n",
      "3. **모델 설정**: 인공지능 모델의 구조를 설정합니다. 여기에는 신경망의 층 수, 각 층의 뉴런 수, 활성화 함수 등의 결정이 포함됩니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 입력하고, 모델이 예측한 결과와 실제 결과 사이의 오류를 계산합니다. 이 오류를 최소화하는 방향으로 모델의 내부 파라미터들(가중치와 편향)을 조정하는 과정을 반복합니다. 이 과정은 역전파 알고리즘을 통해 이루어집니다.\n",
      "\n",
      "5. **평가**: 모델의 성능을 평가합니다. 이는 테스트 데이터를 사용하여 모델의 예측 정확도를 확인하는 것입니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능이 만족스럽지 않다면, 모델의 구조나 학습 방법, 데이터의 전처리 과정 등을 조정하여 성능을 개선합니다.\n",
      "\n",
      "예를 들어, 자율 주행 자동차의 경우, 수많은 도로 상황 이미지 데이터를 학습하여 자동차가 스스로 상황을 판단하고 운전할 수 있도록 하는 것입니다. \n",
      "\n",
      "이러한 학습 과정을 통해 인공지능 모델은 특정 작업을 수행하는 능력을 키우게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# Chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류발생 : {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8db8d",
   "metadata": {},
   "source": [
    "### Runnable의 stream()함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "840000f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 우리의 뇌는 경험을 통해 배우고, 새로운 정보를 기존 지식과 연결하여 기억합니다. 인공지능 모델도 데이터를 통해 배우고, 그 데이터를 분석하여 패턴을 찾고, 미래의 새로운 상황에 대처하는 법을 학습합니다.\n",
      "\n",
      "예를 들어, 사진을 보고 고양이인지 개인지 구분하는 인공지능 모델을 만든다고 가정해 봅시다. 이 모델에게 수많은 고양이와 개의 사진을 보여주고, 이것이 고양이인지 개인지 알려줍니다. 처음에는 모델이 고양이와 개의 구분을 잘 못하지만, 사진을 볼 때마다 조금씩 학습합니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 관련 데이터를 수집합니다. 이 경우, 고양이와 개의 사진들입니다.\n",
      "\n",
      "2. **데이터 분석**: 모델은 수집된 데이터를 분석합니다. 이 분석을 통해 모델은 사진 속에서 고양이와 개의 특징을 찾으려고 합니다. 예를 들어, 고양이는 눈이 크고, 귀가 뾰족하며, 개의 경우 귀가 쳐져 있는 경우가 많다는 등의 특징을 발견할 수 있습니다.\n",
      "\n",
      "3. **모델 업데이트**: 모델은 분석한 특징을 바탕으로 고양이와 개를 구분하는 법을 배웁니다. 처음에는 정확하지 않을 수 있지만, 더 많은 데이터를 학습할수록 점점 더 정확해집니다.\n",
      "\n",
      "4. **예측**: 학습이 완료된 후, 모델은 새로운 사진을 보고 그것이 고양이인지 개인지 예측할 수 있습니다. \n",
      "\n",
      "이러한 학습 과정은 여러 번 반복되며, 모델의 정확도가 높아집니다. 인공지능 모델의 학습 원리는 기본적으로 이러한 반복적인 학습과 개선 과정을 통해 이루어집니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230c581",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "- prompt 1의 출력을 prompt 2의 입력에 사용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 3문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64217427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  **존 윅 (John Wick)**\n",
      "2.  **미션 임파서블: 데드 레콘닝 파트 원**\n",
      "\n",
      "*   **존 윅 (John Wick)**: 은퇴한 전직 암살자 존 윅은 은퇴 후 평화로운 삶을 살고자 하지만, 그의 차를 훔치고 개를 죽인 고어갱이라는 범죄 집단이 그의 삶에 위협을 가합니다. 존 윅은 복수를 위해 모든 것을 희생하며 싸웁니다. 그의 전설적인 실력과 전투 기술을 바탕으로 존 윅은 범죄 조직에 맞서 싸우며, 강력한 적들과의 치열한 전투를 벌입니다.\n",
      "*   **미션 임파서블: 데드 레콘닝 파트 원**: 전 세계의 평화를 위협하는 강력한 인공지능 '엔티티'가 등장합니다. 비밀 정보기관 IMF의 에단 헌트(톰 크루즈)는 동료들과 함께 엔티티를 파괴하기 위한 위험한 임무에 나섭니다. 에단 헌트와 그의 팀은 엔티티를 무찌르고 세계를 구하기 위해 목숨을 건 전투를 벌입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"액션\"})\n",
    "print(response)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463612fb",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81d5313a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Deep learning is a subset of machine learning, which is a type of artificial intelligence (AI). It involves the use of artificial neural networks to analyze data and make decisions. The term \"deep\" refers to the fact that these neural networks are composed of multiple layers, which allow them to learn complex patterns and relationships in data.\n",
      "\n",
      "**Key Characteristics of Deep Learning:**\n",
      "\n",
      "* **Artificial Neural Networks (ANNs):** Deep learning models are based on ANNs, which are inspired by the structure and function of the human brain.\n",
      "* **Multiple Layers:** Deep learning models have multiple layers of interconnected nodes or \"neurons,\" which process and transform inputs to produce outputs.\n",
      "* **Hierarchical Representations:** Each layer in a deep learning model learns to represent the input data at a higher level of abstraction, allowing the model to learn complex patterns and relationships.\n",
      "\n",
      "**How Deep Learning Works:**\n",
      "\n",
      "1. **Data Input:** The model receives input data, such as images, text, or audio.\n",
      "2. **Forward Propagation:** The input data flows through the layers of the model, with each layer applying a set of weights and biases to the input data.\n",
      "3. **Activation Functions:** Each layer applies an activation function to the output, which determines the output of the layer.\n",
      "4. **Backward Propagation:** The model computes the error between its predictions and the actual output, and then propagates the error backwards through the layers to update the weights and biases.\n",
      "5. **Optimization:** The model is optimized using an optimization algorithm, such as stochastic gradient descent (SGD), to minimize the error and improve its performance.\n",
      "\n",
      "**Applications of Deep Learning:**\n",
      "\n",
      "* **Computer Vision:** Image classification, object detection, segmentation, and generation.\n",
      "* **Natural Language Processing (NLP):** Text classification, language translation, and text generation.\n",
      "* **Speech Recognition:** Speech-to-text and voice recognition.\n",
      "* **Robotics:** Control and navigation of robots.\n",
      "\n",
      "**Types of Deep Learning Models:**\n",
      "\n",
      "* **Convolutional Neural Networks (CNNs):** Used for image and video processing.\n",
      "* **Recurrent Neural Networks (RNNs):** Used for sequential data, such as text, speech, and time series data.\n",
      "* **Generative Adversarial Networks (GANs):** Used for generative modeling, such as generating new images or text.\n",
      "\n",
      "**Benefits of Deep Learning:**\n",
      "\n",
      "* **Improved Accuracy:** Deep learning models can achieve state-of-the-art performance on a wide range of tasks.\n",
      "* **Flexibility:** Deep learning models can be applied to a variety of domains and tasks.\n",
      "* **Scalability:** Deep learning models can be trained on large datasets and can scale to complex tasks.\n",
      "\n",
      "**Challenges of Deep Learning:**\n",
      "\n",
      "* **Training Time:** Deep learning models can take a long time to train, especially on large datasets.\n",
      "* **Overfitting:** Deep learning models can suffer from overfitting, which occurs when the model is too complex and performs poorly on new, unseen data.\n",
      "* **Interpretability:** Deep learning models can be difficult to interpret, making it challenging to understand why a particular decision was made.\n",
      "\n",
      "Overall, deep learning is a powerful tool for building AI systems that can learn from data and make accurate predictions or decisions. Its applications are diverse and continue to grow, transforming industries and revolutionizing the way we live and work.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an {topic} expert in AI. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503ebc39",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "예시를 줘서 결과값을 유도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc415c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계의 행성\n",
      "1. **수성**: 가장 작은 행성, 태양과 가깝습니다.\n",
      "2. **금성**: 매우 뜨겁고 밝은 행성입니다.\n",
      "3. **지구**: 생명체가 사는 유일한 행성입니다.\n",
      "4. **화성**: 붉은색이며, 로봇 탐사가 활발합니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가지고 있습니다.\n",
      "7. **천왕성**: 자전축이 기울어져 있습니다.\n",
      "8. **해왕성**: 가장 먼 행성입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "model = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60093c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-build-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
