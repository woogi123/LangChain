{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e68e21",
   "metadata": {},
   "source": [
    "# Ollama\n",
    "Ollama는 대규모 언어 모델 (LLM Large Language Model)을 로컬 머신 상에서 실행하기 위한 도구입니다.\n",
    "\n",
    "- 로컬 실행 :  Ollama는 대규모 언어 모델을 로컬에서 실행할 수 있게 해줍니다.\n",
    "- 데이터 프라이버시 : 로컬에서 모델을 실행하기 때문에 사용자 데이터를 외부 서버로 전송하지 않기 때문에 민감한 데이터를 처리할 때 장점이 있습니다.\n",
    "- 비용 절감 : 클라우드 서비스 사용에 따른 비용을 절감할 수 있습니다.\n",
    "- 모델 커스터마이징 :  특정 도메인에 특화된 데이터로 모델을 재훈련 하거나 튜닝할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605fa9d5",
   "metadata": {},
   "source": [
    "## Model Distillation\n",
    "> 큰 모델의 지식을 작은 모델로 '전달'하는 기술\n",
    "\n",
    "> 모델의 성능(정확도)을 유지하면서 크기를 줄이는 데 초점\n",
    "\n",
    "큰 모델은 정확도는 높지만 계산 속도가 느리고, 하드웨어 자원을 많이 사용합니다. 작은 모델은 빠르고 경량이지만 정확도가 낮을 수 있습니다. 그래서 큰 모델의 \"지식\"을 전달해서, 작은 모델도 가능한 한 비슷한 성능을 내게 만드는 것이 증류의 목표\n",
    "\n",
    "**진행 방식**\n",
    "   1. 큰 모델(teacher model)은 데이터를 학습해서 높은 정확도로 예측합니다.\n",
    "   2. 작은 모델(student model)이 큰 모델의 예측 결과를 참고하면서 데이터를 학습합니다.\n",
    "       - 작은 모델은 단순히 데이터를 보고 배우는 대신, 큰 모델이 \"이 데이터를 이렇게 봐야 한다\"고 가르쳐 주는 방식."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1c9613",
   "metadata": {},
   "source": [
    "## Model Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5549ba5",
   "metadata": {},
   "source": [
    "> 모델이 사용하는 숫자의 정밀도를 낮추어서 처리 속도를 높이고, 메모리 사용량을 줄임\n",
    "\n",
    "AI 모델은 수많은 숫자를 계산해서 정보를 처리하기 때문에 **큰 숫자(32비트, 64비트)로 작업하면 속도가 느려지고, 메모리도 많이 사용**됨. 이런 경우, 정확도를 조금 희생하더라도 **더 작은 숫자(예: 8비트)로 계산**하면 빠르고 효율적\n",
    "\n",
    "Ex. 평소에 온도를 측정할 때 \"1.45272°C\"를 정확히 말하지 않고,  \"1°C\"로 대충 표현해도 충분히 온도를 이해할 수 있음. 이런식으로 정밀도를 살짝 낮춰도 모델이 유용한 결과를 내도록 만드는 과정\n",
    "\n",
    "**진행 방식**\n",
    "1. 기존 모델은 계산에 정밀한 숫자들(예: 32비트 또는 64비트 부동소수점)을 사용합니다.\n",
    "2. 양자화를 통해 이 숫자들을 가볍게 줄이거나 변환합니다(예: 8비트 정수로).\n",
    "3. 결과적으로, 모델의 연산 속도가 빨라지고, 메모리 사용량과 에너지가 줄어듭니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050cac4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
