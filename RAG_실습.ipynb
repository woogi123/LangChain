{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a95ea712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16e249c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain_community faiss-cpu\n",
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4775f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load Data\n",
    "loader = TextLoader(\"data/taxinfo.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2️. Text Split\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_docs = splitter.split_documents(documents)\n",
    "#print(split_docs)\n",
    "\n",
    "# 3️. Indexing (벡터 저장)\n",
    "vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "# 로컬 파일로 저장\n",
    "vectorstore.save_local(\"faiss_index\")\n",
    "\n",
    "# 4️. Retrieval (유사 문서 검색)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
    "# **질문(쿼리)**에 대해 유사한 문서를 검색하는 역할\n",
    "retrieved_docs = retriever.invoke(\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\")\n",
    "#print(retrieved_docs)\n",
    "\n",
    "# 5️. Generation (LLM 응답 생성)\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "#print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4ae045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context 적용한 결과\n",
      "('소득세법 제12조에 따르면 여러 종류의 소득이 비과세소득으로 분류되어 소득세가 부과되지 않습니다. 주요 비과세소득 항목은 다음과 '\n",
      " '같습니다:\\n'\n",
      " '\\n'\n",
      " '1. **공익신탁의 이익**: 「공익신탁법」에 따라 발생하는 공익신탁의 이익은 비과세됩니다.\\n'\n",
      " '\\n'\n",
      " '2. **일부 사업소득**:\\n'\n",
      " '   - **농업 소득**: 논과 밭을 작물 생산에 이용하여 발생하는 소득은 비과세됩니다.\\n'\n",
      " '   - **주택임대소득**: 1개의 주택을 소유한 자의 주택임대소득 중 일부는 비과세됩니다. 단, 제99조에 따른 기준시가가 12억원을 '\n",
      " '초과하는 주택 및 국외에 소재하는 주택의 임대소득은 과세 대상입니다. 또한, 해당 과세기간에 총수입금액의 합계액이 2천만원 이하인 자의 '\n",
      " '주택임대소득(2018년 12월 31일 이전까지 발생하는 소득)은 비과세됩니다.\\n'\n",
      " '   - **농어가부업소득**: 대통령령으로 정하는 농어가부업소득이 비과세됩니다.\\n'\n",
      " '   - **전통주의 제조 소득**: 대통령령으로 정하는 전통주의 제조에서 발생하는 소득은 비과세됩니다.\\n'\n",
      " '   - **임목의 벌채 또는 양도 소득**: 조림기간 5년 이상인 임지의 임목 벌채 또는 양도로 발생하는 연 600만원 이하의 소득은 '\n",
      " '비과세됩니다. 조림기간 및 세액 계산에 관한 사항은 대통령령에 따릅니다.\\n'\n",
      " '   - **작물재배업 소득**: 대통령령으로 정하는 작물재배업에서 발생하는 소득은 비과세됩니다.\\n'\n",
      " '\\n'\n",
      " '이 항목들은 여러 법률 개정을 거쳐 현재의 규정에 이르게 되었으며, 구체적인 사항은 관련 대통령령에 따릅니다. 이를 통해 특정 조건을 '\n",
      " '만족하면 일부 소득은 비과세 혜택을 받을 수 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response_context = llm.invoke(f\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요? 관련 정보: {context}\")\n",
    "print('context 적용한 결과')\n",
    "pprint(response_context.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403b3091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context 적용하지 않은 결과\n",
      "('소득세법에서 비과세소득은 과세 대상에서 제외되어 세금을 부과하지 않는 소득을 의미합니다. 한국 소득세법에 따라 비과세소득으로 인정되는 '\n",
      " '항목에는 다음과 같은 것들이 포함될 수 있습니다:\\n'\n",
      " '\\n'\n",
      " '1. **국민연금 및 기타 공적연금의 일부**: 일정 금액 이하의 연금소득은 비과세로 처리될 수 있습니다.\\n'\n",
      " '   \\n'\n",
      " '2. **고용보험 및 산업재해보상보험에 의한 급여**: 예를 들어 실업급여나 산업재해로 인한 보상금 등이 해당됩니다.\\n'\n",
      " '\\n'\n",
      " '3. **장애인 연금**: 장애인 복지를 위한 일부 연금은 비과세될 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '4. **학자금 및 장학금**: 교육 지원을 목적으로 하는 장학금 중 일정 조건을 충족하는 경우 비과세로 인정됩니다.\\n'\n",
      " '\\n'\n",
      " '5. **일정한 저축성 보험의 환급금**: 일정 요건을 충족하는 저축성 보험의 환급금이 비과세될 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '6. **국가 및 지방자치단체가 지급하는 보조금 중 일부**: 특정한 요건 하에서 제공되는 보조금은 비과세 소득으로 인정됩니다.\\n'\n",
      " '\\n'\n",
      " '7. **기타 법령에 의해 비과세로 규정된 소득**: 법령에 따라 추가적으로 정해진 다양한 비과세 소득 항목들이 있을 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '자세한 사항은 법령 개정에 따라 변경될 수 있으므로, 최신 정보는 한국 국세청이나 관련 법령 문서를 통해 확인하는 것이 좋습니다.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = llm.invoke(f\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\")\n",
    "print('context 적용하지 않은 결과')\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e8e6a7",
   "metadata": {},
   "source": [
    "### 1차 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e9d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개선된 결과:\n",
      "('소득세법 제12조에 따른 비과세소득은 다음과 같이 구분됩니다:\\n'\n",
      " '\\n'\n",
      " '1. **공익신탁 이익**: 공익신탁법에 따른 이익(제12조 1호).\\n'\n",
      " '\\n'\n",
      " '2. **사업소득**: \\n'\n",
      " '   - 작물 생산을 위한 논밭 임대 소득(제12조 2호 가목).\\n'\n",
      " '   - 1주택 소유자의 일정 조건 주택임대소득(제12조 2호 나목).\\n'\n",
      " '   - 농어가부업소득, 전통주 제조 소득 등 대통령령으로 정하는 소득(제12조 2호 다~사목).\\n'\n",
      " '\\n'\n",
      " '3. **근로소득 및 퇴직소득**:\\n'\n",
      " '   - 국외근로 급여, 특정 보험료, 연장근로 수당 등(제12조 3호 거~어목).\\n'\n",
      " '\\n'\n",
      " '4. **기타소득**:\\n'\n",
      " '   - 보훈급여금, 상금, 직무발명보상금 등(제12조 5호 가~자목).\\n'\n",
      " '\\n'\n",
      " '각 항목은 대통령령 등에서 정한 구체적인 조건을 충족해야 비과세 혜택을 받을 수 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from pprint import pprint\n",
    "\n",
    "# 1. 데이터 로드 (기존과 동일)\n",
    "loader = TextLoader(\"data/taxinfo.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. 텍스트 분할 개선\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # 크기 증가\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],  # 자연스러운 분할을 위한 구분자\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "# 3. 인덱싱 (벡터 저장)\n",
    "vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "vectorstore.save_local(\"./db/faiss_index\")\n",
    "\n",
    "# 4. 검색 개선\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",  # 최대 다양성 검색\n",
    "    search_kwargs={\"k\": 5, \"fetch_k\": 10}  # 더 많은 결과 검색\n",
    ")\n",
    "\n",
    "# 5. 프롬프트 엔지니어링\n",
    "def generate_prompt(query, context):\n",
    "    return f\"\"\"다음은 소득세법 비과세소득 관련 조항입니다. 문맥을 고려하여 질문에 답변하세요.\n",
    "\n",
    "[관련 조항]\n",
    "{context}\n",
    "\n",
    "[질문]\n",
    "{query}\n",
    "\n",
    "[답변 요구사항]\n",
    "- 비과세소득 유형을 계층적으로 구분하여 설명\n",
    "- 각 항목별 구체적인 조건 명시\n",
    "- 법조문의 항, 호, 목 번호를 포함\n",
    "- 500자 이내로 간결하게 요약\"\"\"\n",
    "\n",
    "# 검색 및 응답 생성\n",
    "query = \"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.3)  # 창의성 낮춤\n",
    "response = llm.invoke(generate_prompt(query, context))\n",
    "\n",
    "print('개선된 결과:')\n",
    "pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca67f43",
   "metadata": {},
   "source": [
    "### 2차 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "771cd5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 원본 문서 길이 ===\n",
      "전체 문서 길이: 4969 글자\n",
      "분할된 문서 수: 8개\n",
      "=== 분할 예시 ===\n",
      "Chunk 1 (738글자): 제12조(비과세소득) 다음 각 호의 소득에 대해서는 소득세를 과세하지 아니한다. <개정 2010. 12. 27., 2011. 7. 25., 2011. 9. 15., 2012. 2....\n",
      "Chunk 2 (636글자): 다. 대통령령으로 정하는 농어가부업소득\n",
      "    라. 대통령령으로 정하는 전통주의 제조에서 발생하는 소득\n",
      "    마. 조림기간 5년 이상인 임지(林地)의 임목(林木)의 벌채 또는 양...\n",
      "Chunk 3 (792글자): 라. 「근로기준법」 또는 「선원법」에 따라 근로자ㆍ선원 및 그 유족이 받는 요양보상금, 휴업보상금, 상병보상금(傷病補償金), 일시보상금, 장해보상금, 유족보상금, 행방불명보상금, ...\n",
      "\n",
      "=== 검색된 문서 (6개) ===\n",
      "문서 1: 제12조(비과세소득) 다음 각 호의 소득에 대해서는 소득세를 과세하지 아니한다. <개정 2010. 12. 27., 2011. 7. 25., 2011. 9. 15., 2012. 2. 1., 2013. 1. 1., 2013. 3. 22., 2014. 1. 1., 2014. 3. 18., 2014. 12. 23., 2015. 12. 15., 2016. 12. 2...\n",
      "---\n",
      "문서 2: 2) 대학의 교직원 또는 대학과 고용관계가 있는 학생이 소속 대학에 설치된 「산업교육진흥 및 산학연협력촉진에 관한 법률」 제25조에 따른 산학협력단(이하 이 조에서 “산학협력단”이라 한다)으로부터 같은 법 제32조제1항제4호에 따라 받는 보상금\n",
      "    저. 대통령령으로 정하는 복리후생적 성질의 급여\n",
      "4. 연금소득 중 다음 각 목의 어느 하나에 해당하는 소득...\n",
      "---\n",
      "문서 3: 나. 「국가보안법」에 따라 받는 상금과 보로금\n",
      "    다. 「상훈법」에 따른 훈장과 관련하여 받는 부상(副賞)이나 그 밖에 대통령령으로 정하는 상금과 부상\n",
      "    라. 종업원등 또는 대학의 교직원이 퇴직한 후에 사용자등 또는 산학협력단으로부터 지급받거나 대학의 학생이 소속 대학에 설치된 산학협력단으로부터 받는 직무발명보상금으로서 대통령령으로 정하는 금액. ...\n",
      "---\n",
      "문서 4: 4) 종교관련종사자 또는 그 배우자의 출산이나 6세 이하(해당 과세기간 개시일을 기준으로 판단한다) 자녀의 보육과 관련하여 종교단체로부터 받는 금액으로서 월 20만원 이내의 금액\n",
      "    　　　　5) 종교관련종사자가 기획재정부령으로 정하는 사택을 제공받아 얻는 이익\n",
      "    자. 법령ㆍ조례에 따른 위원회 등의 보수를 받지 아니하는 위원(학술원 및 예술원의 회원...\n",
      "---\n",
      "문서 5: 라. 「근로기준법」 또는 「선원법」에 따라 근로자ㆍ선원 및 그 유족이 받는 요양보상금, 휴업보상금, 상병보상금(傷病補償金), 일시보상금, 장해보상금, 유족보상금, 행방불명보상금, 소지품 유실보상금, 장의비 및 장제비\n",
      "    마. 「고용보험법」에 따라 받는 실업급여, 육아휴직 급여, 육아기 근로시간 단축 급여, 출산전후휴가 급여등, 「제대군인 지원에 관한 법...\n",
      "---\n",
      "문서 6: 다. 대통령령으로 정하는 농어가부업소득\n",
      "    라. 대통령령으로 정하는 전통주의 제조에서 발생하는 소득\n",
      "    마. 조림기간 5년 이상인 임지(林地)의 임목(林木)의 벌채 또는 양도로 발생하는 소득으로서 연 600만원 이하의 금액. 이 경우 조림기간 및 세액의 계산 등 필요한 사항은 대통령령으로 정한다.\n",
      "    바. 대통령령으로 정하는 작물재배업에서 발생하...\n",
      "---\n",
      "\n",
      "=== 개선된 프롬프트로 답변 ===\n",
      "('1. 비과세소득의 정의:\\n'\n",
      " '   비과세소득이란 소득세법에 의해 소득세가 부과되지 않는 소득을 의미합니다. 이는 특정한 법적 요건을 충족하는 소득에 대해 세금 부담을 '\n",
      " '경감하거나 면제하기 위한 제도로, 다양한 사회적, 경제적 목적을 달성하기 위해 마련되었습니다.\\n'\n",
      " '\\n'\n",
      " '2. 주요 비과세소득 항목들을 다음과 같이 분류:\\n'\n",
      " '\\n'\n",
      " '   - 사업소득 관련:\\n'\n",
      " '     1) 논ㆍ밭을 작물 생산에 이용하게 함으로써 발생하는 소득\\n'\n",
      " '     2) 1개의 주택을 소유하는 자의 주택임대소득(단, 제99조에 따른 기준시가가 12억원을 초과하는 주택 및 국외에 소재하는 '\n",
      " '주택의 임대소득은 제외)\\n'\n",
      " '     3) 대통령령으로 정하는 농어가부업소득\\n'\n",
      " '     4) 대통령령으로 정하는 전통주의 제조에서 발생하는 소득\\n'\n",
      " '\\n'\n",
      " '   - 근로소득/퇴직소득 관련:\\n'\n",
      " '     1) 대통령령으로 정하는 복무 중인 병(兵)이 받는 급여\\n'\n",
      " '     2) 법률에 따라 동원된 사람이 그 동원 직장에서 받는 급여\\n'\n",
      " '     3) 「산업재해보상보험법」에 따라 수급권자가 받는 요양급여, 휴업급여 등\\n'\n",
      " '     4) 「근로기준법」 또는 「선원법」에 따라 근로자ㆍ선원 및 그 유족이 받는 각종 보상금\\n'\n",
      " '\\n'\n",
      " '   - 연금소득 관련:\\n'\n",
      " '     1) 「국민연금법」, 「공무원연금법」 등 공적연금 관련법에 따라 받는 유족연금, 장애연금 등\\n'\n",
      " '     2) 「산업재해보상보험법」에 따라 받는 각종 연금\\n'\n",
      " '     3) 「국군포로의 송환 및 대우 등에 관한 법률」에 따른 국군포로가 받는 연금\\n'\n",
      " '\\n'\n",
      " '   - 기타소득 관련:\\n'\n",
      " '     1) 「국가유공자 등 예우 및 지원에 관한 법률」에 따라 받는 보훈급여금 등\\n'\n",
      " '     2) 「국가보안법」에 따라 받는 상금과 보로금\\n'\n",
      " '     3) 「상훈법」에 따른 훈장과 관련하여 받는 부상 등\\n'\n",
      " '     4) 종교관련종사자가 받는 학자금, 식사대 등\\n'\n",
      " '     5) 법령ㆍ조례에 따른 위원회 등의 보수를 받지 아니하는 위원이 받는 수당\\n'\n",
      " '\\n'\n",
      " '3. 각 항목별 구체적인 조건이나 한도액 명시:\\n'\n",
      " '\\n'\n",
      " '   - 사업소득 관련:\\n'\n",
      " '     1) 주택임대소득의 경우, 기준시가가 12억원을 초과하는 주택 및 국외에 소재하는 주택의 임대소득은 비과세 대상에서 '\n",
      " '제외됩니다.\\n'\n",
      " '     2) 주택임대소득의 경우, 해당 과세기간에 대통령령으로 정하는 총수입금액의 합계액이 2천만원 이하인 경우에 한정됩니다.\\n'\n",
      " '\\n'\n",
      " '   - 근로소득/퇴직소득 관련:\\n'\n",
      " '     1) 산업재해보상보험법 및 근로기준법에 따른 보상금은 근로의 제공으로 인한 부상ㆍ질병ㆍ사망과 관련된 경우에 비과세됩니다.\\n'\n",
      " '\\n'\n",
      " '   - 연금소득 관련:\\n'\n",
      " '     1) 공적연금 관련법에 따라 받는 연금은 유족연금, 장애연금 등 특정한 종류의 연금에 한정됩니다.\\n'\n",
      " '\\n'\n",
      " '   - 기타소득 관련:\\n'\n",
      " '     1) 종교관련종사자가 받는 금액 중 출산이나 6세 이하 자녀의 보육과 관련하여 받는 금액은 월 20만원 이내의 금액에 '\n",
      " '한정됩니다.')\n",
      "\n",
      "==================================================\n",
      "=== 기존 프롬프트로 답변 ===\n",
      "('소득세법 제12조에 따르면, 비과세소득에 해당하는 소득은 다음과 같습니다:\\n'\n",
      " '\\n'\n",
      " '1. 공익신탁의 이익\\n'\n",
      " '2. 특정 사업소득:\\n'\n",
      " '   - 논ㆍ밭을 작물 생산에 이용하게 함으로써 발생하는 소득\\n'\n",
      " '   - 1개의 주택을 소유하는 자의 주택임대소득 (일정 조건 제외)\\n'\n",
      " '   - 대통령령으로 정하는 농어가부업소득\\n'\n",
      " '   - 대통령령으로 정하는 전통주의 제조에서 발생하는 소득\\n'\n",
      " '3. 근로소득과 퇴직소득 중 특정 소득:\\n'\n",
      " '   - 대통령령으로 정하는 복무 중인 병(兵)이 받는 급여\\n'\n",
      " '   - 법률에 따라 동원된 사람이 그 동원 직장에서 받는 급여\\n'\n",
      " '   - 산업재해보상보험법에 따른 요양급여 등\\n'\n",
      " '   - 근로기준법 또는 선원법에 따른 보상금 등\\n'\n",
      " '4. 연금소득 중 특정 소득:\\n'\n",
      " '   - 공적연금 관련법에 따라 받는 유족연금 등\\n'\n",
      " '   - 산업재해보상보험법에 따른 연금\\n'\n",
      " '   - 국군포로가 받는 연금\\n'\n",
      " '5. 기타소득 중 특정 소득:\\n'\n",
      " '   - 국가유공자 등 예우 및 지원에 관한 법률에 따른 보훈급여금 등\\n'\n",
      " '   - 국가보안법에 따른 상금과 보로금\\n'\n",
      " '   - 상훈법에 따른 훈장 관련 부상 등\\n'\n",
      " '   - 국군포로가 받는 위로지원금 등\\n'\n",
      " '   - 문화유산의 보존 및 활용에 관한 법률에 따른 소득\\n'\n",
      " '   - 종교인소득 중 특정 소득\\n'\n",
      " '   - 법령ㆍ조례에 따른 위원회 등의 수당\\n'\n",
      " '\\n'\n",
      " '이 외에도 대통령령으로 정하는 다양한 소득이 비과세소득으로 규정될 수 있습니다. 각 항목은 관련 법령과 대통령령에 따라 구체적인 조건과 '\n",
      " '범위가 정해집니다.')\n",
      "\n",
      "==================================================\n",
      "=== 검색 방식 개선 테스트 ===\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from pprint import pprint\n",
    "\n",
    "# 1. Load Data\n",
    "loader = TextLoader(\"data/taxinfo.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "print(\"=== 원본 문서 길이 ===\")\n",
    "print(f\"전체 문서 길이: {len(documents[0].page_content)} 글자\")\n",
    "\n",
    "# 2. Text Split 개선\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,  # 500 → 800 (법령 조항이 길어서)\n",
    "    chunk_overlap=150,  # 50 → 150 (맥락 보존 강화)\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # 법령 구조에 맞는 분리자\n",
    ")\n",
    "split_docs = splitter.split_documents(documents)\n",
    "\n",
    "print(f\"분할된 문서 수: {len(split_docs)}개\")\n",
    "print(\"=== 분할 예시 ===\")\n",
    "for i, doc in enumerate(split_docs[:3]):\n",
    "    print(f\"Chunk {i+1} ({len(doc.page_content)}글자): {doc.page_content[:100]}...\")\n",
    "\n",
    "# 3. Indexing\n",
    "vectorstore = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
    "vectorstore.save_local(\"db/faiss_index\")\n",
    "\n",
    "# 4. Retrieval 개선\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\", \n",
    "    search_kwargs={\"k\": 6}  # 2 → 6으로 증가\n",
    ")\n",
    "\n",
    "query = \"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "print(f\"\\n=== 검색된 문서 ({len(retrieved_docs)}개) ===\")\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"문서 {i+1}: {doc.page_content[:200]}...\")\n",
    "    print(\"---\")\n",
    "\n",
    "# 5. Generation - 개선된 프롬프트\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "context = \"\\n\\n\".join([f\"[문서 {i+1}]\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs)])\n",
    "\n",
    "# 개선된 프롬프트 - 더 구체적인 지시사항\n",
    "improved_prompt = f\"\"\"\n",
    "당신은 세무 전문가입니다. 아래 소득세법 제12조 조항을 바탕으로 질문에 답변해주세요.\n",
    "\n",
    "질문: {query}\n",
    "\n",
    "법령 조항:\n",
    "{context}\n",
    "\n",
    "다음 형식으로 답변해주세요:\n",
    "1. 비과세소득의 정의\n",
    "2. 주요 비과세소득 항목들을 다음과 같이 분류:\n",
    "   - 사업소득 관련\n",
    "   - 근로소득/퇴직소득 관련  \n",
    "   - 연금소득 관련\n",
    "   - 기타소득 관련\n",
    "3. 각 항목별 구체적인 조건이나 한도액 명시\n",
    "\n",
    "답변은 법조문을 인용하면서 구체적으로 작성해주세요.\n",
    "\"\"\"\n",
    "\n",
    "# 비교용 - 기존 방식\n",
    "simple_prompt = f\"소득세법에서 비과세소득에 해당하는 소득은 무엇인가요? 관련 정보: {context}\"\n",
    "\n",
    "print(\"\\n=== 개선된 프롬프트로 답변 ===\")\n",
    "response_improved = llm.invoke(improved_prompt)\n",
    "pprint(response_improved.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== 기존 프롬프트로 답변 ===\")\n",
    "response_simple = llm.invoke(simple_prompt)\n",
    "pprint(response_simple.content)\n",
    "\n",
    "# 추가 개선: 다른 검색 방식 시도\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"=== 검색 방식 개선 테스트 ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adcac3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MMR 검색 결과 ===\n",
      "('소득세법 제12조에 따른 비과세소득 항목은 다음과 같이 체계적으로 정리할 수 있습니다.\\n'\n",
      " '\\n'\n",
      " '1. **공익신탁의 이익**\\n'\n",
      " '   - 「공익신탁법」에 따른 공익신탁의 이익\\n'\n",
      " '\\n'\n",
      " '2. **사업소득**\\n'\n",
      " '   - 논ㆍ밭을 작물 생산에 이용하게 함으로써 발생하는 소득\\n'\n",
      " '   - 1개의 주택을 소유하는 자의 주택임대소득 (단, 기준시가가 12억원을 초과하는 주택 및 국외에 소재하는 주택의 임대소득은 '\n",
      " '제외)\\n'\n",
      " '   - 대통령령으로 정하는 농어가부업소득\\n'\n",
      " '   - 대통령령으로 정하는 전통주의 제조에서 발생하는 소득\\n'\n",
      " '   - 조림기간 5년 이상인 임지의 임목의 벌채 또는 양도로 발생하는 소득으로서 연 600만원 이하의 금액\\n'\n",
      " '   - 대통령령으로 정하는 작물재배업에서 발생하는 소득\\n'\n",
      " '   - 대통령령으로 정하는 어로어업 또는 양식어업에서 발생하는 소득\\n'\n",
      " '\\n'\n",
      " '3. **근로소득과 퇴직소득**\\n'\n",
      " '   - 대통령령으로 정하는 복무 중인 병이 받는 급여\\n'\n",
      " '   - 법률에 따라 동원된 사람이 그 동원 직장에서 받는 급여\\n'\n",
      " '   - 「산업재해보상보험법」에 따라 수급권자가 받는 각종 보상금\\n'\n",
      " '   - 「근로기준법」 또는 「선원법」에 따라 근로자ㆍ선원 및 그 유족이 받는 각종 보상금\\n'\n",
      " '   - 「고용보험법」에 따라 받는 실업급여 등\\n'\n",
      " '   - 「국민연금법」에 따라 받는 반환일시금 및 사망일시금\\n'\n",
      " '   - 「공무원연금법」 등 관련 법령에 따라 받는 각종 보상금 및 급여\\n'\n",
      " '   - 대통령령으로 정하는 학자금\\n'\n",
      " '\\n'\n",
      " '4. **연금소득**\\n'\n",
      " '   - 「국민연금법」, 「공무원연금법」 등 공적연금 관련법에 따라 받는 각종 연금\\n'\n",
      " '   - 「산업재해보상보험법」에 따라 받는 각종 연금\\n'\n",
      " '   - 「국군포로의 송환 및 대우 등에 관한 법률」에 따른 연금\\n'\n",
      " '\\n'\n",
      " '5. **기타소득**\\n'\n",
      " '   - 「국가유공자 등 예우 및 지원에 관한 법률」에 따라 받는 보훈급여금 등\\n'\n",
      " '   - 「국가보안법」에 따라 받는 상금과 보로금\\n'\n",
      " '   - 「상훈법」에 따른 훈장과 관련하여 받는 부상 등\\n'\n",
      " '   - 종업원 등이 퇴직 후에 받는 직무발명보상금으로서 대통령령으로 정하는 금액\\n'\n",
      " '   - 「국군포로의 송환 및 대우 등에 관한 법률」에 따라 국군포로가 받는 위로지원금 등\\n'\n",
      " '   - 「문화유산의 보존 및 활용에 관한 법률」에 따라 국가지정문화유산의 양도로 발생하는 소득\\n'\n",
      " '   - 서화ㆍ골동품을 박물관 또는 미술관에 양도함으로써 발생하는 소득\\n'\n",
      " '   - 종교관련종사자가 받는 대통령령으로 정하는 학자금, 식사 또는 식사대, 실비변상적 성질의 지급액\\n'\n",
      " '   - 종교관련종사자 또는 그 배우자의 출산이나 6세 이하 자녀의 보육과 관련하여 종교단체로부터 받는 금액으로서 월 20만원 이내의 '\n",
      " '금액\\n'\n",
      " '\\n'\n",
      " '이와 같은 항목들은 소득세법에 의해 비과세로 규정되어 있어 소득세가 부과되지 않습니다.')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# MMR(Maximum Marginal Relevance) 검색 - 다양성 확보\n",
    "retriever_mmr = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 6, \"fetch_k\": 20}\n",
    ")\n",
    "retrieved_docs_mmr = retriever_mmr.invoke(query)\n",
    "context_mmr = \"\\n\\n\".join([f\"[문서 {i+1}]\\n{doc.page_content}\" for i, doc in enumerate(retrieved_docs_mmr)])\n",
    "\n",
    "response_mmr = llm.invoke(f\"\"\"\n",
    "{query}\n",
    "\n",
    "법령 조항 (MMR 검색):\n",
    "{context_mmr}\n",
    "\n",
    "위 법령을 바탕으로 비과세소득 항목들을 체계적으로 정리해주세요.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=== MMR 검색 결과 ===\")\n",
    "pprint(response_mmr.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494c582",
   "metadata": {},
   "source": [
    "### RAG_PDF_LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2134341c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf\n",
    "\n",
    "import os\n",
    "import json\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# PDF 파일 경로 설정\n",
    "pdf_filepath = 'data/tutorial-korean.pdf'\n",
    "\n",
    "# 파일 존재 여부 확인 (파일이 없으면 오류 발생)\n",
    "if not os.path.exists(pdf_filepath):\n",
    "    raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {pdf_filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea9152cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 39개의 문서가 로드 되었습니다.\n",
      "첫 번째 문서 메타데이터:\n",
      "{\n",
      "  \"producer\": \"Acrobat Distiller with ezUniHFT\",\n",
      "  \"creator\": \"PScript5.dll Version 5.2\",\n",
      "  \"creationdate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"moddate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"author\": \"Owner\",\n",
      "  \"title\": \"<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>\",\n",
      "  \"source\": \"data/tutorial-korean.pdf\",\n",
      "  \"total_pages\": 39,\n",
      "  \"page\": 0,\n",
      "  \"page_label\": \"1\"\n",
      "}\n",
      "\n",
      "10번째 문서 내용: <class 'langchain_core.documents.base.Document'>\n",
      "page_content='11\n",
      "그림 5 와 같이 getRoom과 setRoom 메소드들은 각각 staff 멤버의 방번호(room \n",
      "number)를 설정하고 반환하는 동작을 합니다. getRoom 메소드를 호출해 봅시다. 객체 메뉴의 \n",
      "getRoom 메소드를 선택하여 실행합니다. 그러면 대화상자에서 실행 결과를 볼 수 있을 것\n",
      "입니다(그림 6). 그림 6과 같이 결과의 내용이 \"(unknown room)\"이 됩니다. 왜냐하면, Staff \n",
      "객체에 대한 방번호를 지정하지 않았기 때문입니다.\n",
      "                     \n",
      "그림 6 : 메소드 호출 결과\n",
      "슈퍼 클래스에서 상속된 메소드들은 서브 메뉴(inherited from Person)에서 선택하여 사용\n",
      "할 수 있습니다. 객체 팝업메뉴의 상단에는 두개의 서브메뉴\n",
      "3)가 있을 것입니다. 하나는 \n",
      "Object 클래스로부터 상속 받은 메소드들이고 다른 하나는 Person 클래스로부터 상속 받은 \n",
      "메소드들입니다(그림 5). 따라서, 서브 메뉴를 선택하면 getName과 같은 Person 클래스의 \n",
      "메소드들을 호출할 수 있습니다. getName을 호출해 보세요. 그러면 \"(unknown name)\" \n",
      "이라는 불분명한 결과를 보게 될 것입니다. 왜냐하면 Person 클래스의 name 속성을 지정하지 \n",
      "않았기 때문입니다.\n",
      "이제 방번호(를 지정해 봅시다. 매개변수를 갖는 함수 호출 방법을 알게 될 것입니다. \n",
      "(getRoom과 getName 메소드는 반환값들을 가지지만, 매개변수들은 가지지 않습니다.) 객체 \n",
      "팝업메뉴의 setRoom\n",
      " 메소드를 호출하면 매개변수들을 입력받기 위한 대화상자가 나타납니다. \n",
      "대화상자에 나타나는 프롬프트 위치에 매개변수를 입력하십시오( 그림 7).\n",
      "그림 7 : 매개변수들을 입력받는 메소드 호출 대화상자\n",
      "3)  inherited from Object  ▸\n",
      "    inherited from Person  ▸' metadata={'producer': 'Acrobat Distiller with ezUniHFT', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2005-04-26T15:21:34+09:00', 'moddate': '2005-04-26T15:21:34+09:00', 'author': 'Owner', 'title': '<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>', 'source': 'data/tutorial-korean.pdf', 'total_pages': 39, 'page': 10, 'page_label': '11'}\n",
      "\n",
      "분할된 문서의 개수: 265 타입: <class 'list'>\n",
      "\n",
      "10번째 분할된 문서:\n",
      "page_content='2.3. 리눅스/유닉스 및 기타 시스템에 설치하는 방법 ······························································· 6' metadata={'producer': 'Acrobat Distiller with ezUniHFT', 'creator': 'PScript5.dll Version 5.2', 'creationdate': '2005-04-26T15:21:34+09:00', 'moddate': '2005-04-26T15:21:34+09:00', 'author': 'Owner', 'title': '<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>', 'source': 'data/tutorial-korean.pdf', 'total_pages': 39, 'page': 1, 'page_label': '2'}\n",
      "\n",
      "Lazy Load 방식으로 문서 로드:\n",
      "{\n",
      "  \"producer\": \"Acrobat Distiller with ezUniHFT\",\n",
      "  \"creator\": \"PScript5.dll Version 5.2\",\n",
      "  \"creationdate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"moddate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"author\": \"Owner\",\n",
      "  \"title\": \"<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>\",\n",
      "  \"source\": \"data/tutorial-korean.pdf\",\n",
      "  \"total_pages\": 39,\n",
      "  \"page\": 0,\n",
      "  \"page_label\": \"1\"\n",
      "}\n",
      "{\n",
      "  \"producer\": \"Acrobat Distiller with ezUniHFT\",\n",
      "  \"creator\": \"PScript5.dll Version 5.2\",\n",
      "  \"creationdate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"moddate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"author\": \"Owner\",\n",
      "  \"title\": \"<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>\",\n",
      "  \"source\": \"data/tutorial-korean.pdf\",\n",
      "  \"total_pages\": 39,\n",
      "  \"page\": 1,\n",
      "  \"page_label\": \"2\"\n",
      "}\n",
      "{\n",
      "  \"producer\": \"Acrobat Distiller with ezUniHFT\",\n",
      "  \"creator\": \"PScript5.dll Version 5.2\",\n",
      "  \"creationdate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"moddate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"author\": \"Owner\",\n",
      "  \"title\": \"<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>\",\n",
      "  \"source\": \"data/tutorial-korean.pdf\",\n",
      "  \"total_pages\": 39,\n",
      "  \"page\": 2,\n",
      "  \"page_label\": \"3\"\n",
      "}\n",
      "{\n",
      "  \"producer\": \"Acrobat Distiller with ezUniHFT\",\n",
      "  \"creator\": \"PScript5.dll Version 5.2\",\n",
      "  \"creationdate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"moddate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"author\": \"Owner\",\n",
      "  \"title\": \"<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>\",\n",
      "  \"source\": \"data/tutorial-korean.pdf\",\n",
      "  \"total_pages\": 39,\n",
      "  \"page\": 3,\n",
      "  \"page_label\": \"4\"\n",
      "}\n",
      "{\n",
      "  \"producer\": \"Acrobat Distiller with ezUniHFT\",\n",
      "  \"creator\": \"PScript5.dll Version 5.2\",\n",
      "  \"creationdate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"moddate\": \"2005-04-26T15:21:34+09:00\",\n",
      "  \"author\": \"Owner\",\n",
      "  \"title\": \"<426C75654AC7D1B1DBC6A9C5E4B8AEBEF3B9AEBCAD283230292E687770>\",\n",
      "  \"source\": \"data/tutorial-korean.pdf\",\n",
      "  \"total_pages\": 39,\n",
      "  \"page\": 4,\n",
      "  \"page_label\": \"5\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    # 1. PDF 파일 로드\n",
    "    loader = PyPDFLoader(pdf_filepath)  # PDF 파일을 로드할 객체 생성\n",
    "    docs = loader.load()  # 문서를 전체 로드\n",
    "\n",
    "    # 총 문서 개수 출력\n",
    "    print(f\"총 {len(docs)}개의 문서가 로드 되었습니다.\")\n",
    "\n",
    "    #  첫 번째 문서의 메타데이터 출력\n",
    "    print(\"첫 번째 문서 메타데이터:\")\n",
    "    print(json.dumps(docs[0].metadata, indent=2, ensure_ascii=False))\n",
    "\n",
    "    # 특정 인덱스(10번째) 문서의 내용 확인 (존재할 경우)\n",
    "    if len(docs) > 10:\n",
    "        print(\"\\n10번째 문서 내용:\", type(docs[10]))\n",
    "        print(docs[10])  # 10번째 문서 출력\n",
    "\n",
    "    #  2. 텍스트 분할 (200자 단위, 중첩 없음)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=0)\n",
    "    split_docs = loader.load_and_split(text_splitter=text_splitter)  # 분할된 문서 로드\n",
    "\n",
    "    # 분할된 문서 개수 출력\n",
    "    print(f\"\\n분할된 문서의 개수: {len(split_docs)} 타입: {type(split_docs)}\")\n",
    "\n",
    "    # 10번째 분할된 문서 내용 출력 (존재할 경우)\n",
    "    if len(split_docs) > 10:\n",
    "        print(\"\\n10번째 분할된 문서:\")\n",
    "        print(split_docs[10])\n",
    "\n",
    "    # 3. Lazy Load 방식으로 문서 로드\n",
    "    print(\"\\nLazy Load 방식으로 문서 로드:\")\n",
    "    for i, doc in enumerate(loader.lazy_load()):\n",
    "        if i < 5:  # 너무 많은 출력 방지 (예제: 처음 5개만 출력)\n",
    "            print(json.dumps(doc.metadata, indent=2, ensure_ascii=False))\n",
    "\n",
    "except Exception as e:\n",
    "    # 오류 발생 시 메시지 출력\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a8de367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> 1. 문서 로딩 → PDF 읽기...\n",
      "  총 39페이지 로드 완료\n",
      "==> 2. 문서 분할 → 작은 청크로 나누기\n",
      "  66개 청크 생성 완료\n",
      "  평균 청크 길이: 695자\n",
      "==> 3. 벡터화 → 임베딩으로 변환\n",
      "==> 4. 저장 → FAISS 벡터스토어에 저장\n",
      " FAISS 벡터스토어 생성 완료 (66개 벡터)\n",
      "===> 5. 검색 → 질문과 유사한 문서 찾기\n",
      " Retriever 설정 완료\n",
      "===> 6. 생성 → LLM으로 답변 생성\n",
      " 프롬프트 설정 완료\n",
      "\n",
      " ===> 7.  QA 체인 생성...\n",
      "  RAG 파이프라인 구축 완료!\n",
      "\n",
      "============================================================\n",
      " RAG 시스템 테스트\n",
      "============================================================\n",
      "\n",
      "【테스트 1/5】\n",
      " 질문: BlueJ에서 객체를 생성하는 방법은 무엇인가요?\n",
      " 답변 생성 중...\n",
      "\n",
      " 답변:\n",
      "--------------------------------------------------\n",
      "BlueJ에서 객체를 생성하는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **프로젝트 열기**: 먼저 BlueJ를 시작한 후, 상단 메뉴에서 `Project - Open...`을 선택하여 프로젝트를 엽니다. 예제 프로젝트는 BlueJ 홈 디렉토리의 `examples` 디렉토리에서 찾을 수 있습니다. 예를 들어, `people` 프로젝트를 선택하여 엽니다.\n",
      "\n",
      "2. **객체 생성**: \n",
      "   - 메인 윈도우 중앙에 있는 클래스 아이콘(예: Database, Person, Staff, Student) 중 하나를 선택합니다.\n",
      "   - 클래스 아이콘에서 마우스 오른쪽 버튼을 클릭(매킨토시의 경우, `ctrl+click`)하여 팝업 메뉴를 엽니다.\n",
      "   - 팝업 메뉴에서 생성자 함수를 선택합니다. 이때, 생성할 객체의 이름을 입력받는 대화상자가 나타납니다. 기본적으로 제공되는 이름(예: `staff_1`)을 사용할 수 있습니다.\n",
      "   - `OK` 버튼을 클릭하면 객체가 생성되고, 생성된 객체는 오브젝트 벤치(object bench)에 표시됩니다.\n",
      "\n",
      "3. **추상 클래스 주의**: 추상 클래스(예: Person 클래스)는 객체를 생성할 수 없습니다. 추상 클래스는 객체 생성이 불가능하므로, 이를 직접 확인해 볼 수 있습니다.\n",
      "\n",
      "문서에서 제공된 정보에 따라 위의 단계들을 통해 BlueJ에서 객체를 생성할 수 있습니다. 추가적인 정보는 문서에서 찾을 수 없습니다.\n",
      "\n",
      " 참조 문서:\n",
      "   1. 페이지 7: 8 3.2. 프로젝트 열기 프로젝트란, 관련 있는 여러개의 파일들을 묶어서 관리하기 위한 하나의 작업 단위를 말합니다.  BlueJ 프로젝트는 ...\n",
      "   2. 페이지 9: 10 이 대화상자는 생성할 객체의 이름을 입력받습니다. 또한 동시에 기본적인 이름(staff_1)이  제공됩니다. 이 이름(staff1)은 지금...\n",
      "   3. 페이지 7: 현재 작업중인 어플리케이션에 포함된 클래스들을 아이콘 형식으로 보여주는 것입니다.  클래스 아이콘에서 마우스 오른쪽 버튼을 클릭하면(매킨토시:c...\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "【테스트 2/5】\n",
      " 질문: 컴파일 오류가 발생했을 때 어떻게 확인할 수 있나요?\n",
      " 답변 생성 중...\n",
      "\n",
      " 답변:\n",
      "--------------------------------------------------\n",
      "컴파일 오류가 발생했을 때 확인하는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **에디터를 열기**: 먼저, 소스 코드 파일을 에디터에서 엽니다.\n",
      "\n",
      "2. **컴파일 시도**: 에디터의 상단에 있는 툴바에서 \"Compile\" 버튼을 클릭하여 해당 클래스를 컴파일합니다.\n",
      "\n",
      "3. **오류 메시지 확인**: 만약 구문 오류(syntax error)가 발생하면, 에디터의 아래쪽 정보창(information area)에 오류 메시지가 출력됩니다. 오류가 발생한 라인은 반전되어 표시됩니다.\n",
      "\n",
      "4. **추가 정보 확인**: 정보창의 오른쪽에 있는 물음표를 클릭하면, 발생한 오류 메시지에 대한 추가 정보를 볼 수 있습니다.\n",
      "\n",
      "5. **프로젝트 전체 컴파일**: 프로젝트 윈도우의 툴바에 있는 \"Compile\" 버튼을 클릭하여 전체 프로젝트를 컴파일할 수도 있습니다. 이 경우, 컴파일이 필요한 클래스들만 올바른 순서대로 재컴파일됩니다.\n",
      "\n",
      "6. **에러 발생 시 에디터 열림**: 프로젝트 컴파일 중 에러가 발생하면, 에디터 창이 자동으로 열리며 에러가 발생한 위치와 에러 메시지가 표시됩니다.\n",
      "\n",
      "이러한 단계들을 통해 컴파일 오류를 확인하고 수정할 수 있습니다. 추가적인 도움말이 필요한 경우, 에러 메시지 오른쪽의 물음표를 클릭하여 도움말을 참조하십시오.\n",
      "\n",
      " 참조 문서:\n",
      "   1. 페이지 12: 클래스를 성공적으로 컴파일 하였다면 에디터를 닫으십시오.  프로젝트 윈도우에 툴바 역시 Compile 버튼을 가지고 있습니다. 이 컴파일 기능은...\n",
      "   2. 페이지 12: 13   노트 : 프로젝트를 처음 열었을 때 왜 클래스 아이콘에 체크표시가 되어있지 않은지 궁금할 수  있습니다. people 프로젝트 내의 클...\n",
      "   3. 페이지 13: 14      그림 8 : 컴파일러 에러와 Help 버튼 여기서 모든 에러 메시지들에 대한 도움말이 제공되는 것은 아닙니다. 일부 도움말은 아직...\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "【테스트 3/5】\n",
      " 질문: 디버깅을 위해 중단점을 설정하는 방법을 알려주세요\n",
      " 답변 생성 중...\n",
      "\n",
      " 답변:\n",
      "--------------------------------------------------\n",
      "디버깅을 위해 중단점을 설정하는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **프로젝트 열기**: 먼저, examples 디렉토리 안에 포함된 `debugdemo` 프로젝트를 오픈하십시오. 이 프로젝트는 디버거의 기능을 시연하기 위한 목적으로 만들어진 몇 개의 클래스들을 포함하고 있습니다.\n",
      "\n",
      "2. **클래스 열기**: `Demo` 클래스를 오픈하십시오.\n",
      "\n",
      "3. **메소드 찾기**: `loop` 메소드를 찾으십시오.\n",
      "\n",
      "4. **중단점 설정**:\n",
      "   - `loop` 메소드 코드 중에서 `for` 반복문 내의 임의의 라인에 중단점을 설정하십시오.\n",
      "   - 편집기의 소스코드가 보여지는 곳의 왼쪽 부분이 중단점 영역입니다. 이 영역을 마우스 왼쪽 버튼으로 클릭함으로써 중단점을 설정할 수 있습니다.\n",
      "   - 중단점이 설정되면 작은 stop 표시가 에디터에 나타날 것입니다.\n",
      "\n",
      "이렇게 설정된 중단점은 프로그램 실행 중 해당 지점에서 프로그램을 일시 중단시켜, 현재 상태를 조사할 수 있게 해줍니다.\n",
      "\n",
      " 참조 문서:\n",
      "   1. 페이지 25: 26 7. 디버깅 이 절에서는, BlueJ의 디버깅에 관한 기능들 중에서 가장 중요한 측면을 소개합니다. 컴퓨터  프로그래밍 담당 선생님들은 첫...\n",
      "   2. 페이지 25: 마우스 왼쪽 버튼으로 클릭함으로써 중단점을 설정할 수 있습니다. 작은 stop 표시가 중단점을  의미합니다. 바로 시도해 봅시다. Demo  클...\n",
      "   3. 페이지 28: 없으면 디버거 윈도우를 오픈하십시오. (한편, 프로그램이 실행되는 동안 컴퓨터가 작동하고  있음을 알려주는 상태 표시바를 클릭하므로써 간단히 디...\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "【테스트 4/5】\n",
      " 질문: 코드패드는 무엇이고 어떻게 사용하나요?\n",
      " 답변 생성 중...\n",
      "\n",
      " 답변:\n",
      "--------------------------------------------------\n",
      "코드패드는 BlueJ 프로그래밍 환경에서 자바 코드의 표현식과 명령문을 쉽고 빠르게 평가할 수 있는 기능을 제공합니다. 이를 통해 자바 프로그램 코드의 의미를 상세히 조사하거나 구문을 예증하고 시험하는 데 사용할 수 있습니다.\n",
      "\n",
      "코드패드를 사용하는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **코드패드 나타내기**: \n",
      "   - BlueJ 초기 실행 화면에서는 코드패드가 보이지 않습니다. \n",
      "   - 코드패드를 나타내기 위해서는 '보기' 메뉴에서 '코드패드보기(Show Code Pad)'를 선택하십시오. 그러면 BlueJ 메인 화면의 오른쪽 아래, 즉 오브젝트 벤치의 오른쪽에 코드패드가 나타납니다.\n",
      "   - 코드패드와 오브젝트 벤치 사이의 가로선과 세로선을 조정하여 크기를 변경할 수 있습니다.\n",
      "\n",
      "2. **코드 입력 및 평가**:\n",
      "   - 코드패드 영역에는 자바 표현식 또는 명령문을 입력할 수 있습니다.\n",
      "   - 키보드의 Enter를 누르면 입력된 표현식 또는 명령문이 라인 단위로 평가되어 그 결과가 화면에 나타납니다.\n",
      "\n",
      "3. **객체 생성 및 이동**:\n",
      "   - 코드패드에서 생성된 객체는 작은 객체 아이콘으로 나타납니다.\n",
      "   - 이 객체 아이콘을 오브젝트 벤치로 드래그하여 이동시킬 수 있습니다.\n",
      "\n",
      "4. **객체 검사**:\n",
      "   - 코드패드에서 생성된 객체를 검사하려면 객체 아이콘을 더블클릭하십시오.\n",
      "\n",
      "5. **명령문 실행**:\n",
      "   - 코드패드에 명령문들을 입력하여 실행할 수 있습니다.\n",
      "   - 멀티라인 명령문을 입력하기 위해서는 해당 라인의 끝 부분에서 Shift-Enter를 사용하십시오.\n",
      "\n",
      "6. **입력이력 사용**:\n",
      "   - 코드패드는 사용자가 이전에 입력한 내용들의 이력을 저장합니다.\n",
      "   - 상하 화살표를 이용하여 이전에 입력한 내용을 쉽게 다시 입력하거나 수정하여 재입력할 수 있습니다.\n",
      "\n",
      "이와 같은 기능을 통해 코드패드는 자바 코드의 실험과 테스트를 보다 효율적으로 수행할 수 있도록 도와줍니다.\n",
      "\n",
      " 참조 문서:\n",
      "   1. 페이지 20: 21 6. 코드패드의 사용 BlueJ 코드패드는 자바 코드(표현식과 명령문)의 일부분을 쉽고 빠르게 평가할 수 있는 기능을  제공합니다. 따라서...\n",
      "   2. 페이지 1: 5.2. 클래스 만들기 ···································································...\n",
      "   3. 페이지 36: 37 11. 요약 정리 시작하기 1. 프로젝트를 열기 위해 Project 메뉴에서 Open 을 선택하십시오. 2. 객체를 생성하기 위해서는 클래...\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "【테스트 5/5】\n",
      " 질문: 애플릿을 만들고 실행하는 방법을 설명해주세요\n",
      " 답변 생성 중...\n",
      "\n",
      " 답변:\n",
      "--------------------------------------------------\n",
      "애플릿을 만들고 실행하는 방법은 다음과 같습니다:\n",
      "\n",
      "1. **애플릿 프로젝트 열기**:\n",
      "   - BlueJ의 예제 디렉토리에서 `appletdemo` 프로젝트를 오픈합니다.\n",
      "\n",
      "2. **애플릿 컴파일 및 실행**:\n",
      "   - `appletdemo` 프로젝트 안에는 `CaseConverter`라는 클래스가 있습니다. 이 클래스의 아이콘에는 애플릿임을 나타내는 `<<applet>>` 태그가 표시되어 있습니다.\n",
      "   - 클래스를 컴파일한 후, 클래스의 팝업 메뉴에서 `Run Applet` 명령어를 선택합니다.\n",
      "   - 나타나는 대화상자에서 애플릿을 브라우저에서 실행할지, 애플릿 뷰어에서 실행할지 선택합니다. 기본 설정을 유지하고 `OK` 버튼을 클릭합니다.\n",
      "   - 잠시 후, 애플릿 뷰어가 `CaseConverter` 애플릿을 화면에 보여줍니다.\n",
      "\n",
      "3. **새로운 애플릿 만들기**:\n",
      "   - 일반 클래스처럼 애플릿이 포함된 새로운 클래스를 만듭니다. `New Class` 대화상자에서 타입을 선택할 수 있습니다.\n",
      "   - 컴파일을 하고 나서 애플릿을 실행시킵니다.\n",
      "   - 기본 클래스 골격은 몇 가지 코드가 포함되어 있으며, 이는 2줄의 텍스트로 이루어진 간단한 애플릿을 보여줍니다. 에디터를 열고, 코드를 삽입하여 애플릿을 편집할 수 있습니다.\n",
      "\n",
      "4. **애플릿 테스트하기**:\n",
      "   - 오브젝트 벤치에서 애플릿 객체를 생성할 수 있습니다. 생성자는 애플릿의 팝업 메뉴에서 볼 수 있습니다.\n",
      "   - 오브젝트 벤치에서는 애플릿을 완벽히 실행할 수 없지만, 몇 가지 메소드는 실행할 수 있습니다. 이는 애플릿 구현 부분에서 작성한 메소드를 테스트하는 데 유용합니다.\n",
      "\n",
      "5. **디버깅**:\n",
      "   - 애플릿 내에서 중단점과 한 단계씩 실행 기능을 사용하려면, `AppletWindow` 클래스를 이용해야 합니다. 이 클래스는 BlueJ 환경 하에서 애플릿을 직접 실행시킬 수 있게 해줍니다.\n",
      "   - `AppletWindow` 클래스는 BlueJ 홈페이지의 Resources 메뉴에서 데모와 함께 입수할 수 있습니다.\n",
      "\n",
      "이상은 문서에 기반한 애플릿을 만들고 실행하는 방법입니다. 추가적인 정보는 \"문서에서 찾을 수 없습니다\".\n",
      "\n",
      " 참조 문서:\n",
      "   1. 페이지 31: 32 9. 애플릿 만들기 9.1. 애플릿 실행하기     BuleJ는 어플리케이션 뿐만 아니라 애플릿을 만들고, 실행할 수 있습니다. 예제(ex...\n",
      "   2. 페이지 2: 3 7. 디버깅 ·······································································...\n",
      "   3. 페이지 32: 33 마이크로소프트 윈도우즈나 MAC OS시스템에서, BlueJ는 여러분의 기본 브라우저를 사용 합니다. 유닉스 시스템의 경우는, BlueJ설정...\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "print(\"==> 1. 문서 로딩 → PDF 읽기...\")\n",
    "loader = PyPDFLoader('./data/tutorial-korean.pdf')\n",
    "documents = loader.load()\n",
    "print(f\"  총 {len(documents)}페이지 로드 완료\")\n",
    "\n",
    "print(\"==> 2. 문서 분할 → 작은 청크로 나누기\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,        # 청크 크기 (한국어 최적화)\n",
    "    chunk_overlap=200,      # 중복 부분 (맥락 보존)\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"] # 자연스러운 분할을 위한 구분자\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"  {len(chunks)}개 청크 생성 완료\")\n",
    "print(f\"  평균 청크 길이: {sum(len(chunk.page_content) for chunk in chunks) / len(chunks):.0f}자\")\n",
    "\n",
    "print(\"==> 3. 벡터화 → 임베딩으로 변환\")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",  # 고성능 임베딩 모델\n",
    "    dimensions=1536\n",
    ")\n",
    "\n",
    "print(\"==> 4. 저장 → FAISS 벡터스토어에 저장\")\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "print(f\" FAISS 벡터스토어 생성 완료 ({len(chunks)}개 벡터)\")\n",
    "\n",
    "print(\"===> 5. 검색 → 질문과 유사한 문서 찾기\")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 6}  # 상위 6개 관련 문서 검색\n",
    ")\n",
    "print(\" Retriever 설정 완료\")\n",
    "\n",
    "print(\"===> 6. 생성 → LLM으로 답변 생성\")\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1500\n",
    ")\n",
    "\n",
    "# 한국어 최적화 프롬프트\n",
    "prompt_template = \"\"\"\n",
    "당신은 BlueJ 프로그래밍 환경 전문가입니다. \n",
    "아래 문서 내용을 바탕으로 정확하고 친절한 답변을 제공해주세요.\n",
    "\n",
    "문서 내용:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 규칙:\n",
    "1. 문서 내용만을 근거로 답변하세요\n",
    "2. 단계별 설명이 필요하면 순서대로 작성하세요  \n",
    "3. 구체적인 메뉴명, 버튼명을 포함하세요\n",
    "4. 문서에 없는 정보는 \"문서에서 찾을 수 없습니다\"라고 하세요\n",
    "\n",
    "답변:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "print(\" 프롬프트 설정 완료\")\n",
    "\n",
    "# ===================================\n",
    "# 7. QA 체인 생성\n",
    "# ===================================\n",
    "print(\"\\n ===> 7.  QA 체인 생성...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "print(\"  RAG 파이프라인 구축 완료!\")\n",
    "\n",
    "# ===================================\n",
    "# 8. 테스트 질문들\n",
    "# ===================================\n",
    "test_questions = [\n",
    "    \"BlueJ에서 객체를 생성하는 방법은 무엇인가요?\",\n",
    "    \"컴파일 오류가 발생했을 때 어떻게 확인할 수 있나요?\", \n",
    "    \"디버깅을 위해 중단점을 설정하는 방법을 알려주세요\",\n",
    "    \"코드패드는 무엇이고 어떻게 사용하나요?\",\n",
    "    \"애플릿을 만들고 실행하는 방법을 설명해주세요\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" RAG 시스템 테스트\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ===================================\n",
    "# 9. 질문 및 답변 실행\n",
    "# ===================================\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n【테스트 {i}/5】\")\n",
    "    print(f\" 질문: {question}\")\n",
    "    print(\" 답변 생성 중...\")\n",
    "    \n",
    "    # RAG 실행\n",
    "    result = qa_chain.invoke({\"query\": question})\n",
    "    answer = result[\"result\"]\n",
    "    source_docs = result[\"source_documents\"]\n",
    "    \n",
    "    print(f\"\\n 답변:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(answer)\n",
    "    \n",
    "    # 참조 문서 정보\n",
    "    print(f\"\\n 참조 문서:\")\n",
    "    for j, doc in enumerate(source_docs[:3], 1):\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        preview = doc.page_content[:80].replace('\\n', ' ')\n",
    "        print(f\"   {j}. 페이지 {page}: {preview}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89e68d",
   "metadata": {},
   "source": [
    "### RAG - CharacterTextSplitter\n",
    "- 공백이나 띄어쓰기 기준으로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f87c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 원본 텍스트:\n",
      "--------------------------------------------------\n",
      "RAG는 검색 기반의 텍스트 생성 모델입니다. 기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다. \n",
      "RAG는 검색과 생성 단계를 포함합니다. 먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다.\n",
      "이 방식은 환상(hallucination) 문제를 크게 줄여줍니다. 또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다.\n",
      "\n",
      " 원본 길이: 235자\n",
      "\n",
      "============================================================\n",
      " 다양한 CharacterTextSplitter 설정 비교\n",
      "============================================================\n",
      "\n",
      " 마침표(.) 기준 분할:\n",
      "------------------------------\n",
      "청크 1: 'RAG는 검색 기반의 텍스트 생성 모델입니다' (길이: 24자)\n",
      "청크 2: '기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다' (길이: 32자)\n",
      "청크 3: '특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다' (길이: 32자)\n",
      "청크 4: 'RAG는 검색과 생성 단계를 포함합니다' (길이: 21자)\n",
      "청크 5: '먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다' (길이: 43자)\n",
      "청크 6: '이 방식은 환상(hallucination) 문제를 크게 줄여줍니다' (길이: 36자)\n",
      "청크 7: '또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다' (길이: 33자)\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# ===================================\n",
    "# 예제 텍스트\n",
    "# ===================================\n",
    "text = \"\"\"RAG는 검색 기반의 텍스트 생성 모델입니다. 기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다.\n",
    "특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다. \n",
    "RAG는 검색과 생성 단계를 포함합니다. 먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다.\n",
    "이 방식은 환상(hallucination) 문제를 크게 줄여줍니다. 또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다.\"\"\"\n",
    "\n",
    "print(\" 원본 텍스트:\")\n",
    "print(\"-\" * 50)\n",
    "print(text)\n",
    "print(f\"\\n 원본 길이: {len(text)}자\")\n",
    "\n",
    "# ===================================\n",
    "#  다양한 분할 방식 비교\n",
    "# ===================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" 다양한 CharacterTextSplitter 설정 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 기본 설정 (마침표 기준)\n",
    "print(\"\\n 마침표(.) 기준 분할:\")\n",
    "print(\"-\" * 30)\n",
    "splitter1 = CharacterTextSplitter(\n",
    "    chunk_size=50,      # 청크 최대 크기\n",
    "    chunk_overlap=10,   # 청크 간 중복\n",
    "    separator=\".\"       # 분할 기준\n",
    ")\n",
    "chunks1 = splitter1.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks1, 1):\n",
    "    print(f\"청크 {i}: '{chunk.strip()}' (길이: {len(chunk)}자)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a425c82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 문장 기준 분할 (큰 청크):\n",
      "------------------------------\n",
      "청크 1: 'RAG는 검색 기반의 텍스트 생성 모델입니다. 기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다' (길이: 92자)\n",
      "청크 2: '특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다. \n",
      "RAG는 검색과 생성 단계를 포함합니다' (길이: 56자)\n",
      "청크 3: 'RAG는 검색과 생성 단계를 포함합니다. 먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다' (길이: 66자)\n",
      "청크 4: '먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다.\n",
      "이 방식은 환상(hallucination) 문제를 크게 줄여줍니다' (길이: 81자)\n",
      "청크 5: '이 방식은 환상(hallucination) 문제를 크게 줄여줍니다. 또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다' (길이: 71자)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  문장 기준 (좀 더 큰 청크)\n",
    "print(\"\\n 문장 기준 분할 (큰 청크):\")\n",
    "print(\"-\" * 30)\n",
    "splitter2 = CharacterTextSplitter(\n",
    "    chunk_size=100,     # 더 큰 청크\n",
    "    chunk_overlap=50,   # 더 많은 중복\n",
    "    separator=\".\"\n",
    ")\n",
    "chunks2 = splitter2.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks2, 1):\n",
    "    print(f\"청크 {i}: '{chunk.strip()}' (길이: {len(chunk)}자)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6bdd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 줄바꿈(\\n) 기준 분할:\n",
      "------------------------------\n",
      "청크 1: 'RAG는 검색 기반의 텍스트 생성 모델입니다. 기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다.' (길이: 59자)\n",
      "청크 2: '특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다.' (길이: 33자)\n",
      "청크 3: 'RAG는 검색과 생성 단계를 포함합니다. 먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다.' (길이: 67자)\n",
      "청크 4: '이 방식은 환상(hallucination) 문제를 크게 줄여줍니다. 또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다.' (길이: 72자)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  줄바꿈 기준\n",
    "print(\"\\n 줄바꿈(\\\\n) 기준 분할:\")\n",
    "print(\"-\" * 30)\n",
    "splitter3 = CharacterTextSplitter(\n",
    "    chunk_size=80,\n",
    "    chunk_overlap=0,    # 중복 없음\n",
    "    separator=\"\\n\"\n",
    ")\n",
    "chunks3 = splitter3.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks3, 1):\n",
    "    print(f\"청크 {i}: '{chunk.strip()}' (길이: {len(chunk)}자)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4dafd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 공백(' ') 기준 분할 (단어 단위):\n",
      "------------------------------\n",
      "청크 1: 'RAG는 검색 기반의 텍스트 생성 모델입니다. 기존' (길이: 28자)\n",
      "청크 2: '기존 언어 모델의 단점을 보완하고, 최신 정보를' (길이: 26자)\n",
      "청크 3: '정보를 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데' (길이: 29자)\n",
      "청크 4: '데 강력한 기능을 제공합니다. \n",
      "RAG는 검색과 생성' (길이: 29자)\n",
      "청크 5: '생성 단계를 포함합니다. 먼저 관련 문서를 검색하고,' (길이: 29자)\n",
      "... 총 10개 청크 생성됨\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  공백 기준 (단어 단위)\n",
    "print(\"\\n 공백(' ') 기준 분할 (단어 단위):\")\n",
    "print(\"-\" * 30)\n",
    "splitter4 = CharacterTextSplitter(\n",
    "    chunk_size=30,      # 작은 청크\n",
    "    chunk_overlap=5,\n",
    "    separator=\" \"       # 공백으로 분할\n",
    ")\n",
    "chunks4 = splitter4.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(chunks4[:5], 1):  # 처음 5개만 출력\n",
    "    print(f\"청크 {i}: '{chunk.strip()}' (길이: {len(chunk)}자)\")\n",
    "print(f\"... 총 {len(chunks4)}개 청크 생성됨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a2b7217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " 설정별 결과 요약\n",
      "============================================================\n",
      "마침표 기준 (50자)   :  7개 청크, 평균 31.6자\n",
      "마침표 기준 (100자)  :  5개 청크, 평균 73.2자\n",
      "줄바꿈 기준         :  4개 청크, 평균 57.8자\n",
      "공백 기준          : 10개 청크, 평균 25.9자\n",
      "\n",
      "============================================================\n",
      " chunk_overlap 효과 확인\n",
      "============================================================\n",
      "\n",
      " 중복 없음 (overlap=0):\n",
      "청크 1: 'RAG는 검색 기반의 텍스트 생성 모델입니다'\n",
      "청크 2: '기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다'\n",
      "청크 3: '특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다'\n",
      "청크 4: 'RAG는 검색과 생성 단계를 포함합니다'\n",
      "청크 5: '먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다'\n",
      "청크 6: '이 방식은 환상(hallucination) 문제를 크게 줄여줍니다'\n",
      "청크 7: '또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다'\n",
      "\n",
      " 중복 있음 (overlap=15):\n",
      "청크 1: 'RAG는 검색 기반의 텍스트 생성 모델입니다'\n",
      "청크 2: '기존 언어 모델의 단점을 보완하고, 최신 정보를 제공합니다'\n",
      "청크 3: '특히, 최신 데이터를 반영하는 데 강력한 기능을 제공합니다'\n",
      "청크 4: 'RAG는 검색과 생성 단계를 포함합니다'\n",
      "청크 5: '먼저 관련 문서를 검색하고, 그 다음 검색된 문서를 바탕으로 답변을 생성합니다'\n",
      "청크 6: '이 방식은 환상(hallucination) 문제를 크게 줄여줍니다'\n",
      "청크 7: '또한 실시간으로 최신 정보를 활용할 수 있어 매우 유용합니다'\n",
      "\n",
      "============================================================\n",
      " 실무 활용 팁\n",
      "============================================================\n",
      "\n",
      " 청크 크기 가이드:\n",
      "   • 짧은 문서: 200-500자\n",
      "   • 긴 문서: 500-1000자\n",
      "   • 매우 긴 문서: 1000-2000자\n",
      "\n",
      " chunk_overlap 가이드:\n",
      "   • 일반적: 청크 크기의 10-20%\n",
      "   • 맥락 중요: 청크 크기의 20-30%\n",
      "   • 속도 중요: 0-10%\n",
      "\n",
      " separator 선택:\n",
      "   • 문서: 문단(\n",
      "\n",
      ") 또는 문장(.)\n",
      "   • 코드: 함수나 클래스 단위\n",
      "   • 대화: 발화자 변경 지점\n",
      "\n",
      " RAG 최적화:\n",
      "   • 너무 작으면 맥락 손실\n",
      "   • 너무 크면 관련성 저하\n",
      "   • 적절한 중복으로 연결성 유지\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===================================\n",
    "#  설정별 결과 비교\n",
    "# ===================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" 설정별 결과 요약\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = [\n",
    "    (\"마침표 기준 (50자)\", len(chunks1), chunks1),\n",
    "    (\"마침표 기준 (100자)\", len(chunks2), chunks2),\n",
    "    (\"줄바꿈 기준\", len(chunks3), chunks3),\n",
    "    (\"공백 기준\", len(chunks4), chunks4)\n",
    "]\n",
    "\n",
    "for name, count, chunks in results:\n",
    "    avg_length = sum(len(chunk) for chunk in chunks) / len(chunks)\n",
    "    print(f\"{name:15}: {count:2}개 청크, 평균 {avg_length:.1f}자\")\n",
    "\n",
    "# ===================================\n",
    "#  chunk_overlap 효과 확인\n",
    "# ===================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" chunk_overlap 효과 확인\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 중복 없음\n",
    "splitter_no_overlap = CharacterTextSplitter(\n",
    "    chunk_size=50, chunk_overlap=0, separator=\".\"\n",
    ")\n",
    "chunks_no_overlap = splitter_no_overlap.split_text(text)\n",
    "\n",
    "# 중복 있음\n",
    "splitter_with_overlap = CharacterTextSplitter(\n",
    "    chunk_size=50, chunk_overlap=15, separator=\".\"\n",
    ")\n",
    "chunks_with_overlap = splitter_with_overlap.split_text(text)\n",
    "\n",
    "print(\"\\n 중복 없음 (overlap=0):\")\n",
    "for i, chunk in enumerate(chunks_no_overlap, 1):\n",
    "    print(f\"청크 {i}: '{chunk.strip()}'\")\n",
    "\n",
    "print(\"\\n 중복 있음 (overlap=15):\")\n",
    "for i, chunk in enumerate(chunks_with_overlap, 1):\n",
    "    print(f\"청크 {i}: '{chunk.strip()}'\")\n",
    "    if i > 1:  # 두 번째 청크부터 중복 부분 표시\n",
    "        prev_chunk = chunks_with_overlap[i-2].strip()\n",
    "        curr_chunk = chunk.strip()\n",
    "        # 간단한 중복 확인\n",
    "        if len(prev_chunk) > 10 and len(curr_chunk) > 10:\n",
    "            if prev_chunk[-10:] in curr_chunk:\n",
    "                print(f\"    이전 청크와 중복: '{prev_chunk[-10:]}'\")\n",
    "\n",
    "# ===================================\n",
    "#  실무 팁\n",
    "# ===================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" 실무 활용 팁\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "tips = \"\"\"\n",
    " 청크 크기 가이드:\n",
    "   • 짧은 문서: 200-500자\n",
    "   • 긴 문서: 500-1000자\n",
    "   • 매우 긴 문서: 1000-2000자\n",
    "\n",
    " chunk_overlap 가이드:\n",
    "   • 일반적: 청크 크기의 10-20%\n",
    "   • 맥락 중요: 청크 크기의 20-30%\n",
    "   • 속도 중요: 0-10%\n",
    "\n",
    " separator 선택:\n",
    "   • 문서: 문단(\\n\\n) 또는 문장(.)\n",
    "   • 코드: 함수나 클래스 단위\n",
    "   • 대화: 발화자 변경 지점\n",
    "\n",
    " RAG 최적화:\n",
    "   • 너무 작으면 맥락 손실\n",
    "   • 너무 크면 관련성 저하\n",
    "   • 적절한 중복으로 연결성 유지\n",
    "\"\"\"\n",
    "\n",
    "print(tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617cd93d",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter\n",
    "- 설정된 문자 목록을 순서대로 사용해 가장 적절한 크기로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a2e5ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트:\n",
      "--------------------------------------------------\n",
      "RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.\n",
      "\n",
      "Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.\n",
      "\n",
      "RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.\n",
      "\n",
      "텍스트 길이: 230자\n",
      "\n",
      "============================================================\n",
      "RecursiveCharacterTextSplitter vs CharacterTextSplitter 비교\n",
      "============================================================\n",
      "\n",
      "1. RecursiveCharacterTextSplitter (계층적 분할):\n",
      "---------------------------------------------\n",
      "Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "길이: 27자\n",
      "\n",
      "Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "길이: 67자\n",
      "\n",
      "Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "길이: 72자\n",
      "\n",
      "Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "길이: 58자\n",
      "\n",
      "2. CharacterTextSplitter (단순 분할):\n",
      "-----------------------------------\n",
      "Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다'\n",
      "길이: 58자\n",
      "\n",
      "Chunk 2: '특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다'\n",
      "길이: 35자\n",
      "\n",
      "Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다'\n",
      "길이: 71자\n",
      "\n",
      "Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다'\n",
      "길이: 57자\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 예제 텍스트\n",
    "text = \"\"\"RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
    "\n",
    "이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
    "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.\n",
    "\n",
    "Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.\n",
    "\n",
    "RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.\"\"\"\n",
    "\n",
    "print(\"원본 텍스트:\")\n",
    "print(\"-\" * 50)\n",
    "print(text)\n",
    "print(f\"\\n텍스트 길이: {len(text)}자\")\n",
    "\n",
    "# ===========================================\n",
    "# Recursive vs Character 비교\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RecursiveCharacterTextSplitter vs CharacterTextSplitter 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. RecursiveCharacterTextSplitter (추천)\n",
    "print(\"\\n1. RecursiveCharacterTextSplitter (계층적 분할):\")\n",
    "print(\"-\" * 45)\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=80,\n",
    "    chunk_overlap=20,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \" \", \"\"]  # 우선순위 순서\n",
    ")\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(recursive_chunks):\n",
    "    print(f\"Chunk {i+1}: '{chunk.strip()}'\")\n",
    "    print(f\"길이: {len(chunk)}자\")\n",
    "    print()\n",
    "\n",
    "# 2. CharacterTextSplitter (비교용)\n",
    "print(\"2. CharacterTextSplitter (단순 분할):\")\n",
    "print(\"-\" * 35)\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "simple_splitter = CharacterTextSplitter(\n",
    "    chunk_size=80,\n",
    "    chunk_overlap=20,\n",
    "    separator=\".\"  # 하나의 구분자만 사용\n",
    ")\n",
    "simple_chunks = simple_splitter.split_text(text)\n",
    "\n",
    "for i, chunk in enumerate(simple_chunks):\n",
    "    print(f\"Chunk {i+1}: '{chunk.strip()}'\")\n",
    "    print(f\"길이: {len(chunk)}자\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b90a031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "separators 우선순위 동작 확인\n",
      "============================================================\n",
      "테스트 텍스트:\n",
      "'첫 번째 문단입니다.\\n\\n두 번째 문단입니다.\\n이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?\\n\\n세 번째 문단입니다.'\n",
      "\n",
      "문단 우선 separators=['\\n\\n', '\\n', '.', ' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.'\n",
      "  Chunk 2: '두 번째 문단입니다.'\n",
      "  Chunk 3: '이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?'\n",
      "  Chunk 4: '세 번째 문단입니다.'\n",
      "\n",
      "줄바꿈 우선 separators=['\\n', '.', ' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.\n",
      "\n",
      "두 번째 문단입니다.'\n",
      "  Chunk 2: '이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?'\n",
      "  Chunk 3: '세 번째 문단입니다.'\n",
      "\n",
      "문장 우선 separators=['.', '!', '?', ' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.\n",
      "\n",
      "두 번째 문단입니다'\n",
      "  Chunk 2: '.\n",
      "이 문단은 여러 문장으로 구성됩니다'\n",
      "  Chunk 3: '! 정말 흥미롭죠?\n",
      "\n",
      "세 번째 문단입니다'\n",
      "  Chunk 4: '.'\n",
      "\n",
      "단어 단위 separators=[' ']:\n",
      "  Chunk 1: '첫 번째 문단입니다.\n",
      "\n",
      "두 번째 문단입니다.\n",
      "이 문단은 여러 문장으로'\n",
      "  Chunk 2: '여러 문장으로 구성됩니다! 정말 흥미롭죠?\n",
      "\n",
      "세 번째 문단입니다.'\n",
      "\n",
      "============================================================\n",
      "chunk_size별 분할 결과 비교\n",
      "============================================================\n",
      "\n",
      "chunk_size=50:\n",
      "총 9개 청크 생성\n",
      "평균 청크 길이: 28.8자\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다....' (길이: 27자)\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다....' (길이: 30자)\n",
      "  Chunk 3: '특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고...' (길이: 36자)\n",
      "  Chunk 4: 'Transformer 모델을 기반으로 실시간 정보를 활...' (길이: 47자)\n",
      "  Chunk 5: '활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정...' (길이: 42자)\n",
      "  Chunk 6: '....' (길이: 1자)\n",
      "  Chunk 7: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 ...' (길이: 48자)\n",
      "  Chunk 8: '문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다...' (길이: 27자)\n",
      "  Chunk 9: '....' (길이: 1자)\n",
      "\n",
      "chunk_size=100:\n",
      "총 3개 청크 생성\n",
      "평균 청크 길이: 75.3자\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이...' (길이: 96자)\n",
      "  Chunk 2: 'Transformer 모델을 기반으로 실시간 정보를 활...' (길이: 72자)\n",
      "  Chunk 3: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 ...' (길이: 58자)\n",
      "\n",
      "chunk_size=150:\n",
      "총 2개 청크 생성\n",
      "평균 청크 길이: 114.0자\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.\n",
      "\n",
      "이...' (길이: 96자)\n",
      "  Chunk 2: 'Transformer 모델을 기반으로 실시간 정보를 활...' (길이: 132자)\n",
      "\n",
      "============================================================\n",
      "chunk_overlap 효과 확인\n",
      "============================================================\n",
      "\n",
      "chunk_overlap=0:\n",
      "총 4개 청크 생성\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "  Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "  Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "\n",
      "chunk_overlap=10:\n",
      "총 4개 청크 생성\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "  Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "  Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n",
      "\n",
      "chunk_overlap=30:\n",
      "총 4개 청크 생성\n",
      "  Chunk 1: 'RAG는 검색과 생성 단계를 포함하는 모델입니다.'\n",
      "  Chunk 2: '이 모델은 검색 기반의 텍스트 생성 기능을 제공합니다.\n",
      "특히, 최신 데이터를 반영하는 데 강력한 기능을 가지고 있습니다.'\n",
      "  Chunk 3: 'Transformer 모델을 기반으로 실시간 정보를 활용할 수 있으며, 기존의 단순한 생성 모델보다 더 정확한 답변을 제공합니다.'\n",
      "  Chunk 4: 'RAG의 핵심은 검색과 생성의 결합입니다! 먼저 관련 문서를 찾고, 그 정보를 바탕으로 답변을 만듭니다.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================================\n",
    "# separators 우선순위 테스트\n",
    "# ===========================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"separators 우선순위 동작 확인\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_text = \"\"\"첫 번째 문단입니다.\n",
    "\n",
    "두 번째 문단입니다.\n",
    "이 문단은 여러 문장으로 구성됩니다! 정말 흥미롭죠?\n",
    "\n",
    "세 번째 문단입니다.\"\"\"\n",
    "\n",
    "print(\"테스트 텍스트:\")\n",
    "print(repr(test_text))  # 줄바꿈 문자까지 보이도록\n",
    "\n",
    "# 다양한 separators 설정 테스트\n",
    "separators_configs = [\n",
    "    ([\"\\n\\n\", \"\\n\", \".\", \" \"], \"문단 우선\"),\n",
    "    ([\"\\n\", \".\", \" \"], \"줄바꿈 우선\"),\n",
    "    ([\".\", \"!\", \"?\", \" \"], \"문장 우선\"),\n",
    "    ([\" \"], \"단어 단위\")\n",
    "]\n",
    "\n",
    "for separators, description in separators_configs:\n",
    "    print(f\"\\n{description} separators={separators}:\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=40,\n",
    "        chunk_overlap=10,\n",
    "        separators=separators\n",
    "    )\n",
    "    chunks = splitter.split_text(test_text)\n",
    "    \n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"  Chunk {i}: '{chunk.strip()}'\")\n",
    "\n",
    "# ===========================================\n",
    "# chunk_size별 결과 비교\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"chunk_size별 분할 결과 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "chunk_sizes = [50, 100, 150]\n",
    "\n",
    "for size in chunk_sizes:\n",
    "    print(f\"\\nchunk_size={size}:\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=size,\n",
    "        chunk_overlap=20,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    \n",
    "    print(f\"총 {len(chunks)}개 청크 생성\")\n",
    "    avg_length = sum(len(chunk) for chunk in chunks) / len(chunks)\n",
    "    print(f\"평균 청크 길이: {avg_length:.1f}자\")\n",
    "    \n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"  Chunk {i}: '{chunk.strip()[:30]}...' (길이: {len(chunk)}자)\")\n",
    "\n",
    "# ===========================================\n",
    "# chunk_overlap 효과 확인\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"chunk_overlap 효과 확인\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "overlap_values = [0, 10, 30]\n",
    "\n",
    "for overlap in overlap_values:\n",
    "    print(f\"\\nchunk_overlap={overlap}:\")\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=80,\n",
    "        chunk_overlap=overlap,\n",
    "        separators=[\"\\n\\n\", \".\", \" \"]\n",
    "    )\n",
    "    chunks = splitter.split_text(text)\n",
    "    \n",
    "    print(f\"총 {len(chunks)}개 청크 생성\")\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        print(f\"  Chunk {i}: '{chunk.strip()}'\")\n",
    "        \n",
    "        # 중복 부분 확인\n",
    "        if i > 1 and overlap > 0:\n",
    "            prev_chunk = chunks[i-2].strip()\n",
    "            curr_chunk = chunk.strip()\n",
    "            # 간단한 중복 확인 (마지막 10자와 첫 10자 비교)\n",
    "            if len(prev_chunk) >= 10 and len(curr_chunk) >= 10:\n",
    "                prev_end = prev_chunk[-10:]\n",
    "                curr_start = curr_chunk[:10]\n",
    "                if any(word in curr_start for word in prev_end.split() if len(word) > 2):\n",
    "                    print(f\"    중복 감지: 이전 청크와 겹치는 부분 있음\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a94850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "실무 활용 가이드\n",
      "============================================================\n",
      "\n",
      "RecursiveCharacterTextSplitter 사용 가이드:\n",
      "\n",
      "1. 기본 설정 (일반적 문서):\n",
      "   chunk_size=1000, chunk_overlap=200\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \".\", \" \"]\n",
      "\n",
      "2. 한국어 문서 최적화:\n",
      "   chunk_size=500-1000, chunk_overlap=100-200\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \".\", \"。\", \" \"]\n",
      "\n",
      "3. 코드 문서:\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \"\t\", \" \"]\n",
      "\n",
      "4. 대화/채팅 로그:\n",
      "   separators=[\"\n",
      "\n",
      "\", \"\n",
      "\", \":\", \" \"]\n",
      "\n",
      "장점:\n",
      "- 의미 단위로 자연스러운 분할\n",
      "- 계층적 구분자로 최적화된 분할점 찾기\n",
      "- 텍스트 특성에 맞는 유연한 설정\n",
      "\n",
      "주의사항:\n",
      "- chunk_size는 LLM 토큰 제한 고려\n",
      "- chunk_overlap은 맥락 보존과 비용의 균형\n",
      "- separators 순서가 분할 품질 결정\n",
      "\n",
      "\n",
      "프로그램 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================================\n",
    "# 활용 가이드\n",
    "# ===========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"실무 활용 가이드\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\"\"\n",
    "RecursiveCharacterTextSplitter 사용 가이드:\n",
    "\n",
    "1. 기본 설정 (일반적 문서):\n",
    "   chunk_size=1000, chunk_overlap=200\n",
    "   separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "\n",
    "2. 한국어 문서 최적화:\n",
    "   chunk_size=500-1000, chunk_overlap=100-200\n",
    "   separators=[\"\\n\\n\", \"\\n\", \".\", \"。\", \" \"]\n",
    "\n",
    "3. 코드 문서:\n",
    "   separators=[\"\\n\\n\", \"\\n\", \"\\t\", \" \"]\n",
    "\n",
    "4. 대화/채팅 로그:\n",
    "   separators=[\"\\n\\n\", \"\\n\", \":\", \" \"]\n",
    "\n",
    "장점:\n",
    "- 의미 단위로 자연스러운 분할\n",
    "- 계층적 구분자로 최적화된 분할점 찾기\n",
    "- 텍스트 특성에 맞는 유연한 설정\n",
    "\n",
    "주의사항:\n",
    "- chunk_size는 LLM 토큰 제한 고려\n",
    "- chunk_overlap은 맥락 보존과 비용의 균형\n",
    "- separators 순서가 분할 품질 결정\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n프로그램 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b00ae",
   "metadata": {},
   "source": [
    "### TokenTextSplitter\n",
    "- token기준 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22835464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 텍스트 미리보기:\n",
      " Semantic Search (의미론적 검색)\n",
      "\n",
      "정의: 사용자의 질의를 단순한 키워드 매칭이 아니라 문맥과 의미를 분석하여 관련 정보를 반환하는 검색 방식.\n",
      "예시: \"우주 탐사\"를 검색하면 \"아폴로 11호\", \"화성 탐사 로버\"와 같은 연관 정보가 포함된 결과를 제공함.\n",
      "연관 키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
      "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
      "\n",
      "Embedding (임베딩)\n",
      "\n",
      "정의: 단어나 문장을 벡터 공간에 매핑하여 의미적으로 유사한 것들이 가까이 위치하도록 하는 기법.\n",
      "예시: \"강아지\"와 \"고양이\"의 벡터 표현이 \n",
      "\n",
      " 총 14개의 청크로 분할됨.\n",
      "\n",
      " 첫 번째 청크:\n",
      " Semantic Search (의미론적 검색)\n",
      "\n",
      "정의: 사용자의 질의를 단순한 키워드 매칭이 아니라 문맥과 의미를 분석하여 관련 정보를 반환하는 검색 방식.\n",
      "예시: \"우주 탐사\"를 검색하면 \"아폴로 11호\", \"화성 탐사 로버\"와 같은 연관 정보가 포함된 결과를 제공함.\n",
      "연관 키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대�\n",
      "\n",
      " Chunk 1 (길이: 270):\n",
      "Semantic Search (의미론적 검색)\n",
      "\n",
      "정의: 사용자의 질의를 단순한 키워드 매칭이 아니라 문맥과 의미를 분석하여 관련 정보를 반환하는 검색 방식.\n",
      "예시: \"우주 탐사\"를 검색하면 \"아폴로 11호\", \"화성 탐사 로버\"와 같은 연관 정보가 포함된 결과를 제공함.\n",
      "연관 키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대�\n",
      "\n",
      " Chunk 2 (길이: 229):\n",
      "성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
      "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
      "\n",
      "Embedding (임베딩)\n",
      "\n",
      "정의: 단어나 문장을 벡터 공간에 매핑하여 의미적으로 유사한 것들이 가까이 위치하도록 하는 기법.\n",
      "예시: \"강\n",
      "\n",
      " Chunk 3 (길이: 233):\n",
      "까이 위치하도록 하는 기법.\n",
      "예시: \"강아지\"와 \"고양이\"의 벡터 표현이 유사하게 위치함.\n",
      "연관 키워드: 벡터화, 자연어 처리, 딥러닝\n",
      "\n",
      "Token (토큰)\n",
      "\n",
      "정의: 텍스트 데이터를 더 작은 단위(단어, 문자, 문장 등)로 나누는 과정.\n",
      "예시: \"AI는 혁신적이다\"를 [\"AI\", \"는\", \"혁신적\", \"이다\"]로 분할.\n",
      "연관 키워드: 토큰화, NLP, 텍스트 전처리\n",
      "\n",
      "Transformer (트랜스포머)\n",
      "\n",
      "정의: 자\n",
      "\n",
      " Chunk 4 (길이: 237):\n",
      "�리\n",
      "\n",
      "Transformer (트랜스포머)\n",
      "\n",
      "정의: 자연어 처리에서 사용되는 신경망 아키텍처로, 병렬 연산과 장기 의존성 처리가 강점.\n",
      "예시: GPT, BERT 등의 모델이 트랜스포머 기반으로 동작함.\n",
      "연관 키워드: 딥러닝, 자기 주의 메커니즘, NLP\n",
      "\n",
      "Self-Attention (자기 주의 메커니즘)\n",
      "\n",
      "정의: 문장의 모든 단어가 서로에게 가중치를 부여하여 문맥을 이해하는 방식.\n",
      "예시: \"나는 강아지를 좋아한다\"에서 \"\n",
      "\n",
      " Chunk 5 (길이: 237):\n",
      ".\n",
      "예시: \"나는 강아지를 좋아한다\"에서 \"나는\"과 \"좋아한다\"가 강한 연관성을 가짐.\n",
      "연관 키워드: 트랜스포머, BERT, 문맥 학습\n",
      "\n",
      "Fine-Tuning (미세 조정)\n",
      "\n",
      "정의: 사전 학습된 모델을 특정 작업에 맞게 추가 학습하는 과정.\n",
      "예시: GPT 모델을 법률 문서 요약에 맞게 학습.\n",
      "연관 키워드: 전이 학습, 모델 최적화, AI 응용\n",
      "\n",
      "Zero-shot Learning (제로샷 학습)\n",
      "\n",
      "정의: 특정 태스크에 대한\n"
     ]
    }
   ],
   "source": [
    "# %pip install tiktoken\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "# 파일 읽기\n",
    "with open(\"./data/ai_terminology.txt\", encoding=\"utf-8\") as f:\n",
    "    file = f.read()  # 파일 내용을 읽어오기\n",
    "\n",
    "print(\"원본 텍스트 미리보기:\\n\", file[:500])  # 앞 500자 출력\n",
    "\n",
    "# TokenTextSplitter 설정\n",
    "text_splitter = TokenTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=200,  # 청크 크기\n",
    "    chunk_overlap=20,  # 청크 간 겹치는 부분 추가하여 문맥 유지\n",
    "    encoding_name=\"cl100k_base\",  # OpenAI tiktoken 기본 인코딩 사용 (한글 처리 개선)\n",
    "    add_start_index=True  # 각 청크의 시작 인덱스 반환\n",
    ")\n",
    "\n",
    "# 텍스트 분할 실행\n",
    "texts = text_splitter.split_text(file)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"\\n 총 {len(texts)}개의 청크로 분할됨.\")\n",
    "print(\"\\n 첫 번째 청크:\\n\", texts[0])\n",
    "\n",
    "# 청크 길이 확인\n",
    "for i, chunk in enumerate(texts[:5]):  # 처음 5개만 확인\n",
    "    print(f\"\\n Chunk {i+1} (길이: {len(chunk)}):\\n{chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d72b6f",
   "metadata": {},
   "source": [
    "### HuggingFaceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a8ec148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 321, which is longer than the specified 300\n",
      "Created a chunk of size 362, which is longer than the specified 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 원본 텍스트 미리보기:\n",
      " Semantic Search (의미론적 검색)\n",
      "\n",
      "정의: 사용자의 질의를 단순한 키워드 매칭이 아니라 문맥과 의미를 분석하여 관련 정보를 반환하는 검색 방식.\n",
      "예시: \"우주 탐사\"를 검색하면 \"아폴로 11호\", \"화성 탐사 로버\"와 같은 연관 정보가 포함된 결과를 제공함.\n",
      "연관 키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      "FAISS (Faceboo\n",
      "\n",
      " 총 23개의 청크로 분할됨\n",
      "\n",
      " Chunk 1 (25자):\n",
      "Semantic Search (의미론적 검색)\n",
      "\n",
      " Chunk 2 (157자):\n",
      "정의: 사용자의 질의를 단순한 키워드 매칭이 아니라 문맥과 의미를 분석하여 관련 정보를 반환하는 검색 방식.\n",
      "예시: \"우주 탐사\"를 검색하면 \"아폴로 11호\", \"화성 탐사 로버\"와 같은 연관 정보가 포함된 결과를 제공함.\n",
      "연관 키워드: 자연어 처리, 검색 알고리즘, 데이터 마이닝\n",
      "\n",
      " Chunk 3 (37자):\n",
      "FAISS (Facebook AI Similarity Search)\n",
      "\n",
      " Chunk 4 (176자):\n",
      "정의: FAISS는 페이스북에서 개발한 고속 유사성 검색 라이브러리로, 특히 대규모 벡터 집합에서 유사 벡터를 효과적으로 검색할 수 있도록 설계되었습니다.\n",
      "예시: 수백만 개의 이미지 벡터 중에서 비슷한 이미지를 빠르게 찾는 데 FAISS가 사용될 수 있습니다.\n",
      "연관키워드: 벡터 검색, 머신러닝, 데이터베이스 최적화\n",
      "\n",
      " Chunk 5 (143자):\n",
      "Embedding (임베딩)\n",
      "\n",
      "정의: 단어나 문장을 벡터 공간에 매핑하여 의미적으로 유사한 것들이 가까이 위치하도록 하는 기법.\n",
      "예시: \"강아지\"와 \"고양이\"의 벡터 표현이 유사하게 위치함.\n",
      "연관 키워드: 벡터화, 자연어 처리, 딥러닝\n",
      "\n",
      "Token (토큰)\n",
      "\n",
      "\n",
      " 첫 번째 청크의 토큰 개수: 23\n",
      " 첫 번째 청크의 토큰 리스트: ['Sem', 'antic', 'ĠSearch', 'Ġ(', 'ìĿ', 'ĺ', 'ë', '¯', '¸', 'ë', '¡', 'ł', 'ì', 'ł', 'ģ', 'Ġ', 'ê', '²', 'Ģ', 'ì']\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# GPT-2 모델의 토크나이저 로드\n",
    "hf_tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "# 데이터 파일 읽기\n",
    "file_path = \"./data/ai_terminology.txt\"\n",
    "with open(file_path, encoding=\"utf-8\") as f:\n",
    "    file_content = f.read()\n",
    "\n",
    "print(\" 원본 텍스트 미리보기:\\n\", file_content[:200])\n",
    "\n",
    "# CharacterTextSplitter 설정 (Hugging Face 토크나이저 사용)\n",
    "text_splitter = CharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    hf_tokenizer,\n",
    "    chunk_size=300,  # 각 청크 크기 (토큰 기준 아님)\n",
    "    chunk_overlap=50,  # 청크 간 중복 부분\n",
    ")\n",
    "\n",
    "# 텍스트 분할 수행\n",
    "split_texts = text_splitter.split_text(file_content)\n",
    "\n",
    "# 분할된 텍스트 출력\n",
    "print(f\"\\n 총 {len(split_texts)}개의 청크로 분할됨\\n\")\n",
    "for i, chunk in enumerate(split_texts[:5]):  # 처음 5개만 출력\n",
    "    print(f\" Chunk {i+1} ({len(chunk)}자):\\n{chunk}\\n\")\n",
    "\n",
    "# 토크나이저로 텍스트를 토큰 단위로 변환하여 확인\n",
    "tokenized_example = hf_tokenizer.tokenize(split_texts[0])\n",
    "print(f\"\\n 첫 번째 청크의 토큰 개수: {len(tokenized_example)}\")\n",
    "print(\" 첫 번째 청크의 토큰 리스트:\", tokenized_example[:20])  # 앞 20개만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5797ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-build-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
